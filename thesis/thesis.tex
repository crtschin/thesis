\documentclass[11pt, final]{article}
\usepackage{mystyle}

\addbibresource{./references.bib}

\input{definitions.tex}

\setlength{\headheight}{15pt}
\pagestyle{fancy}
\lhead{Utrecht University}
\rfoot{\thepage}
\cfoot{ }
\allowdisplaybreaks

\begin{document}

\input{titlepage.tex}
\newpage

\input{abstract.tex}
\newpage

\pagenumbering{arabic}
\setcounter{page}{3}
\tableofcontents
\newpage

\input{introduction}

\section{Background}

\input{ad.tex}
\input{denotational.tex}
\input{coq.tex}
\input{logical_relation.tex}

\section{Formalizing Forward-Mode AD}
  The formalization of the forward-mode automatic differentiation macro will be explained in the following sections.
  The formal proof will start from a base simply-typed lambda calculus enriched with product types and incrementally add both sum and array types.
  Also included in the final language is an implementation of primitive recursion using integer types.
  Many of the theorems and lemmas will stay consistent between sections as the overarching correctness statement does not change.
  Later section only add their respective cases to the corresponding proofs of the lemmas.

  \subsection{Simply Typed Lambda Calculus}\label{sec:formal_stlc}
  % Talk about simply typed lambda calculus,
  % Something about Λ_δ^{+, *, R}
  % Give examples of functions
  % talk about denotations and
  As mentioned in background section~\ref{sec:language_repr}, we will make use of De-Bruijn indices in a intrinsic representation to formulate our language.
  Both addition and multiplication are included as operations on the real numbers.
  Our base language consists of the simply-typed lambda calculus with product types and real numbers, hereby referenced as $\Lambda_{\delta}^{\times, \rightarrow, R}$, where $\delta$ consists of the addition and multiplication operators.

  Both the language constructs and the typing rules for this language are standard for a simply typed lambda calculus, as shown in \ref{fig:base_infer}.
  As expected we include variables, applications and abstractions in the \<var>, \<app> and \<abs> constructors.
  Product types are added to the language in the form of binary projections, \<first> and \<second> to represent respectively the left and right projections of \<tuple> terms.
  For real numbers, \<rval> is used to introduce real numbered constants and \<add> and \<mul> will be used to respectively encode addition and multiplication.

  \begin{figure}
    \begin{mathpar}
      \inferrule*[Right=\textsc{TVar}]
        {elem\ n\ \Gamma = \tau}
        {\Gamma \vdash var\ n : \tau} \and
      \inferrule*[Right=\textsc{TAbs}]
        {(\sigma, \Gamma) \vdash t : \tau}
        {\Gamma \vdash abs\ t : \sigma \rightarrow \tau} \\ \and
      \inferrule*[Right=\textsc{TApp}]
        {\Gamma \vdash t1 : \sigma \rightarrow \tau \\
          \Gamma \vdash t2 : \sigma}
        {\Gamma \vdash app\ t1\ t2 : \tau} \\ \and
      \inferrule*[Right=\textsc{TTuple}]
        {\Gamma \vdash t1 : \tau \\
          \Gamma \vdash t2 : \sigma}
        {\Gamma \vdash tuple\ t1\ t2 : \tau \times \sigma} \\ \and
      \inferrule*[Right=\textsc{TFst}]
        {\Gamma \vdash t : \tau \times \sigma}
        {\Gamma \vdash first\ t : \tau} \and
      \inferrule*[Right=\textsc{TSnd}]
        {\Gamma \vdash t : \tau \times \sigma}
        {\Gamma \vdash second\ t : \sigma} \\ \and
      \inferrule*[Right=\textsc{TRval}]
        {r \in \<R>}
        {\Gamma \vdash rval\ r : R} \\ \and
      \inferrule*[Right=\textsc{TAdd}]
        {\Gamma \vdash r1 : R \\
          \Gamma \vdash r2 : R \\ }
        {\Gamma \vdash add\ r1\ r2 : R} \and
      \inferrule*[Right=\textsc{TMull}]
        {\Gamma \vdash r1 : R \\
        \Gamma \vdash r2 : R \\ }
      {\Gamma \vdash mul\ r1\ r2 : R} \and
    \end{mathpar}
    \caption{Type-inferrence rules for $\lambdaBase$}
    \label{fig:base_infer}
  \end{figure}

  % How we translated this into the well-typed intrinsic representation
  These can be translated into Coq definitions in a reasonably straightforward manner, with each case keeping track of both how the typing context and types change.
  In the \<var> case we need some way to determine what type the variable is referencing.
  Like many others previously\cite{Benton2011}\cite{Coquand1994}, instead of using indices into the list accompanied with a proof that the index does not exceed the length of the list, we make use of an inductively defined type evidence to type our variables as shown in \ref{lst:strong_stlc}.
  The cases for \<app> and \<abs> are as expected, where variables in the body of abstraction are able to reference their respective arguments.

  Notably, in the original proof by Huot, Staton, and \Vakar{} \cite{huot2020correctness}, they make use of n-ary products accompanied with pattern matching expressions.
  We opted to implement binary projection products, as they are conceptually simpler while still retaining much of the same functionality expected of product types.

  % \begin{listing}
  %   \begin{minted}{coq}
  % Definition Ctx : Type := list ty.

  % Inductive tm ~(\Gamma : Ctx) : ty \rightarrow Type~ :=
  %   (* Base STLC *)
  %   | var : ~forall \tau,
  %     \tau ∈ \Gamma \rightarrow tm \Gamma \tau~
  %   | app : ~forall \tau \sigma,
  %     tm \Gamma (\sigma \Rightarrow \tau) \rightarrow
  %     tm \Gamma \sigma \rightarrow
  %     tm \Gamma \tau~
  %   | abs : ~forall \tau \sigma,
  %     tm (\sigma::\Gamma) \tau \rightarrow tm \Gamma (\sigma \Rightarrow \tau)~

  %   (* Operations on real numbers *)
  %   | const : ~R \rightarrow tm \Gamma Real~
  %   | add : ~tm \Gamma Real \rightarrow tm \Gamma Real \rightarrow tm \Gamma Real~
  %   | mul : ~tm \Gamma Real \rightarrow tm \Gamma Real \rightarrow tm \Gamma Real~

  %   (* Binary projection products *)
  %   | tuple : ~forall {\tau \sigma},
  %     tm \Gamma \tau \rightarrow
  %     tm \Gamma \sigma \rightarrow
  %     tm \Gamma (\tau \times \sigma)~
  %   | first : ~forall {\tau \sigma}, tm \Gamma (\tau \times \sigma) \rightarrow tm \Gamma \tau~
  %   | second : ~forall {\tau \sigma}, tm \Gamma (\tau \times \sigma) \rightarrow tm \Gamma \sigma~
  %   \end{minted}
  %   \caption{\<Coq> definition of the base lambda calculus}
  %   \label{lst:stlc_base}
  % \end{listing}

  We use the same inductively defined macro on types and terms used by many previous authors to implement the forward-mode automatic differentiation macro\cite{huot2020correctness}\cite{barthe2020versatility}\cite{Shaikha2019}.
  The forward-mode macro, $\D$, keeps track of both primal and tangent traces using tuples as respectively its first and second elements.
  In most cases, the macro simply preserves the structure of the language.
  The cases for real numbers such as addition and multiplication are the exception.
  Here, the element encoding the tangent trace needs to contain the proper syntactic translation of the derivative of the operation.

  \begin{figure}
    \centering
    \begin{equation*}
      \begin{split}
        \D(\<R>) &= \<R> \times \<R> \\
        \D(\tau \times \sigma) &= \D(\tau) \times \D(\sigma) \\
        \D(\tau \rightarrow \sigma) &= \D(\tau) \rightarrow \D(\sigma)
      \end{split}
      \begin{split}
        \D(\rval{n}) &= \tuple{(\rval{n})}{(\rval{0})} \\
        \D(\add{n}{m}) &= \tuple{(\add{n}{m})}{(\add{n'}{m'})} \\
        \D(\mul{n}{m}) &= \tuple{(\mul{n}{m})} \\
          &{(\add{(\mul{n'}{m})}{(\mul{m'}{n})})})
      \end{split}
    \end{equation*}
    \caption{Macro on base simply-typed lambda calculus}
    \label{eqn:macro_base}
  \end{figure}

  This is implemented by destructing the recursive calls to $\<D>$ to access the syntactic counterparts of the primal and tangent denotations.
  Note that applying the macro to variables do nothing exceptional as the macro is also applied to the typing context, so variables implicitly already reference macro-applied terms.

  Due to restricting our language to be total and excluding constructs related to partiality such as general recursion and iteration, it suffices to give our language a set-theoretic denotational semantics.
  Like the type evidences, well-typed terms will denotate to functions $\llbracket \Gamma \rrbracket \rightarrow \llbracket \tau \rrbracket$.

  \begin{figure}
    \centering
    \begin{equation*}
      \begin{split}
        \llbracket \<R> \rrbracket &= \<denoteR> \\
        \llbracket \tau \times \sigma \rrbracket &=
          \llbracket \tau \rrbracket * \llbracket \sigma \rrbracket \\
        \llbracket \tau \rightarrow \sigma \rrbracket &= \llbracket \tau \rrbracket \rightarrow \llbracket \sigma \rrbracket \\
        \\
        \llbracket \<Top> \rrbracket &= \<hd> \\
        \llbracket \<Pop>\ v \rrbracket &= \<tl> \circ \llbracket v \rrbracket \\
      \end{split}
      \;\;\;
      \begin{split}
        \llbracket \var{v} \rrbracket &=
          \lambda x. lookup\ \llbracket v \rrbracket\ x \\
        \llbracket \app{t_1}{t_2} \rrbracket &=
          \lambda x. (\llbracket t_1 \rrbracket(x)) (\llbracket t_2 \rrbracket(x)) \\
        \llbracket \abs{t} \rrbracket &=
          \lambda x\ y. \llbracket t \rrbracket(y :: x) \\
        \llbracket \add{t_1}{t_2} \rrbracket &=
          \lambda x. \llbracket t_1 \rrbracket(x) + \llbracket t_2 \rrbracket(x) \\
        \llbracket \mul{t_1}{t_2} \rrbracket &=
          \lambda x. \llbracket t_1 \rrbracket(x) * \llbracket t_2 \rrbracket(x) \\
        \llbracket \tuple{t_1}{t_2} \rrbracket &=
          \lambda x. (\llbracket t_1 \rrbracket(x), \llbracket t_2 \rrbracket(x)) \\
        \llbracket \first{t} \rrbracket &=
          \lambda x. let\ (x, y) = \llbracket t \rrbracket(x)\ in\ x \\
        \llbracket \second{t} \rrbracket &=
          \lambda x. let\ (x, y) = \llbracket t \rrbracket(x)\ in\ y \\
      \end{split}
    \end{equation*}
    \caption{Denotations of the base simply-typed lambda calculus}
    \label{eqn:lr_base}
  \end{figure}

  For any type $\tau$, simply swap out the syntactic type to its corresponding \<Coq> variant in \<Type>.
  So the syntactic \<R> will denotate to the $\<denoteR>$ type in \<Coq>.
  Denotating the terms in our language now corresponds to finding the appropriate inhabitants in the denotated types.
  We denotate our typing contexts $\Gamma$, lists of types, as heterogeneous lists containing their corresponding denotations.
  The specific implementation of heterogeneous lists used, correspond to the one given by Adam Chlipala\cite{ChlipalaCPDT}.

  When working through giving the constructs in our language the proper denotations, most of the cases are straightforward.
  Notable is the case for variables, where we made use of an inductively defined evidence to type our terms.
  As denotations, these evidences wil correspond to lookups into our heterogeneous lists to their appropriate types.

  % \begin{listing}
  %   \begin{minted}{coq}
  %   \end{minted}
  %   \caption{Denotatonal semantics for types, typing contexts and lookups.}
  %   \label{lst:denotation_types}
  % \end{listing}

  % \begin{listing}
  %   \begin{minted}{coq}
  %   \end{minted}
  %   \caption{Denotatonal semantics for the base simply-typed lambda calculus.}
  %   \label{lst:denotation_base}
  % \end{listing}

  % In the section denotation
  % Explain expressiveness of base language
  % Work out examples
  As mentioned by by Barthe, et. al.\cite{barthe2020versatility}, this small calculus, $\lambdaBase$, accompanied with the arguably simple set-theoretic denotational semantics is expressive enough to encode the higher-order polynomials containing the addition and multiplication operators.

  \begin{example}[Square]
    $abs\ (mul\ (var\ Top)\ (var\ Top))$ denotates to the square function $\lambda x. x * x$.
    \begin{proof}
      This follows from the definition of our denotation functions.
      \begin{align*}
        \llbracket abs\ &(mul\ (var\ Top)\ (var\ Top)) \rrbracket\ [] \\
          &\equiv \lambda x.
            \llbracket mul\ (var\ Top)\ (var\ Top) \rrbracket\ [x] \\
          &\equiv \lambda x.
            \llbracket var\ Top \rrbracket\ [x] *
              \llbracket var\ Top \rrbracket\ [x] \\
          &\equiv \lambda x. x * x \qedhere
      \end{align*}
    \end{proof}
  \end{example}

  % TODO: give reasonable examples

  As we work with denotations, smooth functions $f : \<R>^n -> \<R>$ can be interpreted as the denotations of a corresponding syntactic term $x_1, \dots, x_n \vdash t : R$.
  Intuitively, the free variables in the term $t$ denote the usages of the parameters of the function and as such are restricted to terms of type $R$, same as each of the arguments in the function $f$.
  Note that while both the arguments and result type of $t$ are restricted to $R$, $t$ itself can consist of higher order types.

  Although Barthe, et. al.\cite{barthe2020versatility} gave a syntactic proof of correctness of the macro, our proof follows the more denotational style of proof given by Huot, Staton and \Vakar{}\cite{huot2020correctness}.
  Correctness of the forward-mode macro consists of the assertion that the denotation of any macro-applied term of type $x_1 : R, \dots, x_n : R \vdash t : \<R>$ will result in a pair of both the denotation of the original term and the derivative of that denotation.

  Likewise, the proof of correctness will follow a logical relations argument, first generalizing the statement for both the typing contexts and the result type.
  The relation will ensure that both the derivability property and the derivatives are preserved over higher-order types.
  We define the logical relation as a type-indexed relation between denotations of both terms and their macro-applied variants, so for any type $\tau$, $S_\tau$ is the relation between functions $R \rightarrow \llbracket \tau \rrbracket$ and $R \rightarrow \llbracket \D(\tau) \rrbracket$.

  \begin{equation}
    S_\tau(f, g) =
      \left\{
        \begin{array}{ll}
          smooth\ f \wedge
            g = \lambda x. (f(x), \frac{\partial f}{\partial x}(x))
            & : \tau = R \\
          \exists f_1, f_2, g_1, g_2,
            & : \tau = \sigma \times \rho \\
            \;\;\;\;S_\sigma(f_1, f_2), S_\sigma(g_1, g_2). \\
            \;\;\;\;f = \lambda x. (f_1(x), g_1(x)) \wedge \\
            \;\;\;\;g = \lambda x. (f_2(x), g_2(x)) \\
          \forall f_1, f_2.
            & : \tau = \sigma \rightarrow \rho \\
            \;\;\;\;S_\sigma(f_1, f_2) \Rightarrow \\
            \;\;\;\;S_\rho(\lambda x. f(x)(f_1(x)),\lambda x. f(x)(f_2(x)))
        \end{array}
      \right.
  \label{eqn:lr_base}
  \end{equation}

  The next step involves proving that syntactically well-typed terms are semantically correct.
  In other words, the relation needs to be proven valid for any term $x_1 : R, \dots, x_n : R \vdash t : \tau$ and argument function $f : R \rightarrow R^n$ such that $S_\tau(\llbracket t \rrbracket \circ f, \llbracket \D(t) \rrbracket \circ \D_n \circ f)$.

  To properly instantiate the arguments to the denotation of the macro-applied term, an auxiliary function is needed that pairs each constant with their derivative $0$. So it transforms $f : R \rightarrow \llbracket R^n \rrbracket$ into $\D_n(f, x) : R \rightarrow \llbracket \D(R)^n \rrbracket$.
  The full type signature of the function becomes $\D_n : (R \rightarrow \llbracket R^n \rrbracket) \rightarrow R \rightarrow \llbracket \D(R)^n \rrbracket$, which essentially accompanies each argument supplied by $f$ with its accompanying derivative.

  \begin{equation}
    \D_n(f, x) =
      \left\{
        \begin{array}{ll}
          f(x) & : n = 0 \\
          ((hd \circ f)(x)), \frac{\partial{(hd \circ f)}}{\partial{x}}(x)) :: \D_{n'}(tl \circ f, x) & : n = S(n') \\
        \end{array}
      \right.
  \label{eqn:argument_df}
  \end{equation}

  Proving this statement directly by induction on the typing derivation, however, does not work.
  As expected in a logical relations proof, the indicative issue lies in both the case for applications and abstractions.
  To make this work, the correctness statement needs to be generalized to arbitrary contexts and implicitly, substitutions.

  If this were a syntactic proof, one would need to show that relation is preserved when applying substitutions consisting of arbitrary terms, possibly containing higher-order constructs.
  In this style of proof, the same concept needs to be incorporated in the argument function $f$, which intuitively speaking, supplies the terms referenced by variables through the typing context.

  % TODO: attempt to do this?

  To prove this statement, it first needs to be generalized to arbitrary substitutions.
  The key in formulating these denotationally lies in what was previously the argument function $f : R \rightarrow R^n$.
  Previously the function was used to indicate the open variables or function arguments.
  If generalized to $\Gamma = x_1 : \tau_1, \dots, x_n : \tau_n$, this same function could be seen as a function which supplies terms foreach open variable $x_1, \dots, x_n$ with their appropriate types.
  So the argument function now becomes the pair of functions $s : R \rightarrow \llbracket \Gamma \rrbracket$ and $s_D : R \rightarrow \llbracket \D(\Gamma) \rrbracket$.
  Note that the functions $s$ and $s_D$ are built out of the denotations of terms such that these same denotations follow the logical relation (\ref{eqn:lr_base}) for our language.
  We phrase this requirement as a definition.

  \begin{definition}(Instantiation)
    Substitutional functions $s : R \rightarrow \llbracket \Gamma \rrbracket$ and $s_D : R \rightarrow \llbracket \D(\Gamma) \rrbracket$ are inductively instantiated such that they follow
    \begin{equation}
      inst_\Gamma(f, g) =
        \left\{
          \begin{array}{ll}
            f = const([]) \wedge g = const([])
              & : \Gamma = [] \\
            \forall f_1, f_2, g_1, g_2.
              & : \Gamma = (\tau :: \Gamma') \\
              \;\;inst_{\Gamma'}(f_1, g_1) \wedge S_\tau(f_2, g_2) \\
              \;\;\;\; \implies f = \lambda x. (f_2(x) :: f_1(x)) \wedge \\
              \;\;\;\;\;\; g = \lambda x. (g_2(x) :: g_1(x))
          \end{array}
        \right.
    \label{eqn:lr_base}
    \end{equation}
  \end{definition}

  Using this notion of substitution instantiations we can now formulate our substitution lemma.

  \begin{lemma}[Substitution]\label{thm:substitution_lemma}
    For any well-typed term $\Gamma \vdash t : \tau$, and instantiation functions $s : R \rightarrow \llbracket \Gamma \rrbracket$ and $s_D : R \rightarrow \llbracket \D(\Gamma) \rrbracket$ such that they follow $inst_\Gamma(s, s_D)$, then $S_\tau(\llbracket t\rrbracket \circ s, \llbracket \D(t)\rrbracket \circ s_D)$.
  \end{lemma}

  \begin{proof}

    This is proven by induction on the typing derivation of $t$.
    Unless otherwise specified, the type of $s$ and $s_D$ are respectively $R \rightarrow \llbracket \Gamma \rrbracket$ and $R \rightarrow \llbracket \D(\Gamma) \rrbracket$.
    \begin{enumerate}
      \item (\<var>)

        Prove: $S_\tau(\llbracket var\ v \rrbracket \circ s, \llbracket \D(var\ v) \rrbracket \circ s_D)$.

        Proceed by induction on the type evidence $v$.
        \begin{itemize}
          \item(\<Top>) Base case

          Prove: $S_\tau(\llbracket var\ Top \rrbracket \circ s, \llbracket \D(var\ Top) \rrbracket \circ s_D)$, where $s : R \rightarrow \llbracket \tau :: \Gamma \rrbracket$ and $s_D : R \rightarrow \llbracket \tau :: \Gamma \rrbracket$

          In this case the referenced $\tau$ exists at the top of the list.
          So both $\llbracket var\ Top \rrbracket$ and $\llbracket \D(var\ Top) \rrbracket$ denotate to fetching the top term.
          This is now proven by definition of $inst$, which states that the the term is semantically well-typed.

          \begin{align*}
            S&_\tau(\llbracket var\ Top \rrbracket \circ s, \llbracket \D(var\ Top) \rrbracket \circ s_D) \\
            &\Vdash \text{(Definition of $\D$)} \\
            & S_\tau(\llbracket var\ Top \rrbracket \circ s, \llbracket var\ Top \rrbracket \circ s_D) \\
            &\Vdash \text{(Definition of $\circ$)} \\
            & S_\tau(\lambda x. \llbracket var\ Top \rrbracket (s(x)), \lambda x. \llbracket var\ Top \rrbracket (s_D(x))) \\
            &\Vdash \text{(Definition of $\llbracket\rrbracket$)} \\
            & S_\tau(\lambda x. lookup\ \llbracket Top \rrbracket (s(x)), \lambda x. lookup\ \llbracket Top \rrbracket (s_D(x))) \\
            &\Vdash \text{(Rewrite using $s = \lambda x. hd(s(x))::tl(s(x))$)} \\
            & S_\tau(\lambda x. lookup\ \llbracket Top \rrbracket (hd(s(x))::tl(s(x))), \\
              & \;\;\; \lambda x. lookup\ \llbracket Top \rrbracket (hd(s_D(x))::tl(s_D(x)))) \\
            & \Vdash \text{(Simplify with lookup and $\llbracket Top \rrbracket$)} \\
            & S_\tau(\lambda x. hd(s(x)), \lambda x. hd(s_D(x))) \\
            & \Vdash \text{(By definition of $inst_{\tau::\Gamma}$)} \\
          \end{align*} \qed

          \item(\<Pop>) Induction step

          Prove: $S_\tau(\llbracket var\ (Pop\ v) \rrbracket \circ s, \llbracket \D(var\ (Pop\ v)) \rrbracket \circ s_D)$, where $s : R \rightarrow \llbracket \sigma :: \Gamma \rrbracket$ and $s_D : R \rightarrow \llbracket \D(\sigma :: \Gamma) \rrbracket$.

          Induction hypothesis:
          \begin{enumerate}\label{eqn:subst_ih_var_Pop}
            \item $\forall (f : R \rightarrow \llbracket \Gamma \rrbracket), (g : R \rightarrow \llbracket \D(\Gamma) \rrbracket). \\
            \;\;\;S_\tau(\llbracket var\ v \rrbracket \circ f, \llbracket \D(var\ v) \rrbracket \circ g)$
          \end{enumerate}

          Note that the \<var> term now denotates to ignoring the arbitrary unrelated type $\sigma$ and looking up $v$ in the rest of the list $\Gamma$.
          So $S_\tau(\llbracket var\ v \rrbracket \circ tl \circ s, \llbracket \D(var\ v) \rrbracket \circ tl \circ s_D)$, which is proven using the induction hypothesis by respectively instantiating $f$ and $g$ as $tl \circ s$ and $tl \circ s_D$.

          \begin{align*}
            S&_\tau(\llbracket var\ (Pop\ v) \rrbracket \circ s, \llbracket \D(var\ (Pop\ v)) \rrbracket \circ s_D) \\
            &\Vdash \text{(Definition of $\D$)} \\
            & S_\tau(\llbracket var\ (Pop\ v) \rrbracket \circ s, \llbracket var\ (Pop\ v) \rrbracket \circ s_D) \\
            &\Vdash \text{(Definition of $\circ$)} \\
            & S_\tau(\lambda x. \llbracket var\ (Pop\ v) \rrbracket (s(x)), \lambda x. \llbracket var\ (Pop\ v) \rrbracket (s_D(x))) \\
            &\Vdash \text{(Definition of $\llbracket\rrbracket$)} \\
            & S_\tau(\lambda x. lookup\ \llbracket Pop\ v \rrbracket (s(x)), \lambda x. lookup\ \llbracket Pop\ v \rrbracket (s_D(x))) \\
            &\Vdash \text{(Rewrite using $s = \lambda x. hd(s(x))::tl(s(x))$)} \\
            & S_\tau(\lambda x. lookup\ \llbracket Pop\ v \rrbracket (hd(s(x))::tl(s(x))), \\
              & \;\;\; \lambda x. lookup\ \llbracket Pop\ v \rrbracket (hd(s_D(x))::tl(s_D(x)))) \\
            & \Vdash \text{(Simplify with lookup and $\llbracket Pop\ v \rrbracket$)} \\
            & S_\tau(\lambda x. lookup\ \llbracket v \rrbracket (tl(s(x))), \lambda x. lookup\ \llbracket v \rrbracket (tl(s_D(x)))) \\
            & \Vdash \text{(Use IH. \ref{eqn:subst_ih_var_Pop} with $f = tl(s(x))$ and $g = tl(s_D(x))$)}
          \end{align*} \qed
        \end{itemize}
      \item (\<app>)

        Prove: $S_\tau(\llbracket app\ t_1\ t_2 \rrbracket \circ s, \llbracket \D(app\ t_1\ t_2) \rrbracket \circ s_D)$

        Induction hypotheses:
        \begin{enumerate}
          \item \label{eqn:subst_ih_app1}$S_{\sigma\rightarrow\tau}(\llbracket t_1 \rrbracket \circ s, \llbracket \D(t_1) \rrbracket \circ s_D)$
          \item \label{eqn:subst_ih_app2}$S_{\sigma}(\llbracket t_2 \rrbracket \circ s, \llbracket \D(t_2) \rrbracket \circ s_D)$
        \end{enumerate}

        First it is useful to rewrite the induction hypothesis \ref{eqn:subst_ih_app1} in a more usable format. Rewrite the statement using the definition of $S$ at function types.

        \begin{align*}
          S&_{\sigma\rightarrow\tau}(\llbracket t_1 \rrbracket \circ s, \llbracket \D(t_1) \rrbracket \circ s_D) \\
            & \Vdash \text{(Definition of \circ)} \\
            & S_{\sigma\rightarrow\tau}(\lambda x. \llbracket t_1 \rrbracket(s(x)), \lambda x. \llbracket \D(t_1) \rrbracket(s_D(x))) \\
            & \Vdash \text{(Definition of $S_{\rightarrow}$)} \\
            & \forall f_1, f_2.
              S_{\sigma}(f1, f2) \rightarrow \\
            &S_\tau(\lambda x. (\llbracket t_1 \rrbracket(s(x)))(f_1(x)), \lambda x. (\llbracket \D(t_1) \rrbracket(s_D(x)))(f_2(x)))
        \end{align*}

        The case for \<app> is now proven by applying the induction hypothesis \ref{eqn:subst_ih_app1} for the function term using the induction hypothesis \ref{eqn:subst_ih_app2} for the argument term to satify its premise.

        \begin{align*}
          S&_\tau(\llbracket app\ t_1\ t_2 \rrbracket \circ s, \llbracket \D(app\ t_1\ t_2) \rrbracket \circ s_D) \\
            &\Vdash \text{(Definition of $\D$)}\\
            & S_\tau(\llbracket app\ t_1\ t_2 \rrbracket \circ s, \llbracket app\ \D(t_1)\ \D(t_2) \rrbracket \circ s_D) \\
            &\Vdash \text{(Definition of \circ)}\\
            & S_\tau(\lambda x. \llbracket app\ t_1\ t_2 \rrbracket (s (x)), \lambda x. \llbracket app\ \D(t_1)\ \D(t_2) \rrbracket (s_D (x))) \\
            &\Vdash \text{(Definition of $\llbracket \rrbracket$)}\\
            & S_\tau(\lambda x. (\llbracket t_1\ \rrbracket(s(x))) (\llbracket t_2 \rrbracket(s(x))),\lambda x. (\llbracket \D(t_1)\ \rrbracket(s_D(x))) (\llbracket \D(t_2) \rrbracket(s_D(x))) \\
            &\Vdash \text{(Induction hypothesis \ref{eqn:subst_ih_app1})}\\
            & S_{\sigma}(\lambda x. \llbracket t_2 \rrbracket (s(x)), \lambda x. \llbracket \D(t_2) \rrbracket \circ (s_D(x))) \\
            &\Vdash \text{(Induction hypothesis \ref{eqn:subst_ih_app2})}
        \end{align*} \qed
      \item (\<abs>)

        Prove: $S_{\sigma\rightarrow\tau}(\llbracket abs\ t \rrbracket \circ s, \llbracket \D(abs\ t) \rrbracket \circ s_D)$

        Induction hypothesis:
        \begin{enumerate}
          \item \label{eqn:subst_ih_abs} $S_\sigma(\llbracket t \rrbracket \circ s, \llbracket \D(t) \rrbracket \circ s_D)$, where $s : R \rightarrow \llbracket \sigma::\Gamma \rrbracket$ and $s_D : R \rightarrow \llbracket \sigma::\Gamma \rrbracket$
        \end{enumerate}

        As is the case for \ref{eqn:subst_ih_app1}, simplify the goal statement using the definition of $S_\rightarrow$. So the proof obligation now becomes.

        Prove: $S_{\tau}(\lambda x. (\llbracket abs\ t \rrbracket (s(x)))(f_1(x)), \lambda x. (\llbracket \D(abs\ t) \rrbracket (s_D(x)))(f_2(x)))$

        Assume:
        \begin{enumerate}
          \item $f_1 : R \rightarrow \llbracket \sigma \rrbracket$
          \item $f_2 : R \rightarrow \llbracket \D(\sigma) \rrbracket$
          \item \label{eqn:subst_ass_abs3} $S_\sigma(f_1, f_2)$
        \end{enumerate}

        The proof proceeds by rewriting the goal until we can apply the induction hypothesis.
        Note that the assumption \ref{eqn:subst_ass_abs3}: $S_\sigma(f_1, f_2)$ ensures that the requirement of $inst_{\sigma::\Gamma}$ in the induction hypothesis \ref{eqn:subst_ih_abs} is satisfied.

        \begin{align*}
          S&_{\tau}(\lambda x. (\llbracket abs\ t \rrbracket (s(x)))(f_1(x)), \lambda x. (\llbracket \D(abs\ t) \rrbracket (s_D(x)))(f_2(x))) \\
            &\Vdash \text{(Definition of $\D$)}\\
            & S_{\tau}(\lambda x. (\llbracket abs\ t \rrbracket (s(x)))(f_1(x)), \lambda x. (\llbracket abs\ \D(t) \rrbracket (s_D(x)))(f_2(x))) \\
            &\Vdash \text{(Definition of $\llbracket \rrbracket$)}\\
            & S_{\tau}(\lambda x. (\llbracket t \rrbracket (f_1(x) :: s(x))), \lambda x. (\llbracket \D(t) \rrbracket (f_2(x) :: s_D(x)))) \\
            &\Vdash \text{(Induction hypothesis \ref{eqn:subst_ih_app1})}
        \end{align*} \qed

      \item (\<rval>)

      Prove: $S_{R}(\llbracket rval\ n \rrbracket \circ s, \llbracket \D(rval\ n) \rrbracket \circ s_D)$

      This is proven by noting that the corresponding denotations of \<rval> are constant functions, which are both smooth and whose derivatives are equal to $0$.

      \begin{align*}
        S&_R(\llbracket rval\ n \rrbracket \circ s, \llbracket \D(rval\ n) \rrbracket \circ s_D) \\
        &\Vdash \text{(Definition of $\D$)}\\
        &S_R(\llbracket rval\ n \rrbracket \circ s, \llbracket tuple\ (rval\ n)\ (rval\ 0) \rrbracket \circ s_D) \\
        &\Vdash \text{(Definition of $\llbracket\rrbracket$)}\\
        &S_R(const\ n, (const\ n, const\ 0)) \\
        &\Vdash \text{(Definition of $S_R$)}\\
        &smooth\ (const\ n) \wedge
          const\ 0 = \sfrac{\partial{const\ n}}{\partial{x}} \\
        &\Vdash \text{(split goals: goal 1)}\\
        &\;\;\;smooth\ (const\ n) \\
        &\;\;\;\Vdash \text{($f(x) = n$ is continuously differentiable)}\\
        &\Vdash \text{(split goals: goal 2)}\\
        &\;\;\;const\ 0 = \sfrac{\partial{const\ n}}{\partial{x}} \\
        &\;\;\;\Vdash \text{(if $f(x) = n$, then $\sfrac{\partial{f}}{\partial{x}} = 0$)}
      \end{align*} \qed
      \item (\<add>)

      Prove: $S_R(\llbracket add\ t_1\ t_2 \rrbracket \circ s, \llbracket \D(add\ t_1\ t_2) \rrbracket \circ s_D)$

      Induction hypotheses:
      \begin{enumerate}
        \item \label{eqn:subst_ih_add1}$S_R(\llbracket t_1 \rrbracket \circ s, \llbracket \D(t_1) \rrbracket \circ s_D)$
        \item \label{eqn:subst_ih_add2}$S_R(\llbracket t_2 \rrbracket \circ s, \llbracket \D(t_2) \rrbracket \circ s_D)$
      \end{enumerate}

      The proof proceeds by simplifying the denotations and proving the smoothness and derivative requirements for $S_R$.

      \begin{align*}
        S&_R(\llbracket add\ t_1\ t_2 \rrbracket \circ s, \llbracket \D(add\ t_1\ t_2) \rrbracket \circ s_D) \\
        &\Vdash \text{(Definition of $\D$)}\\
        &S_R(\llbracket add\ t_1\ t_2 \rrbracket \circ s, \llbracket tuple\ \\
        & \;\;\;(add\ (first\ \D(t_1)) (first\ \D(t_2)))\ \\
        & \;\;\;(add\ (second \D(t_1)) (second \D(t_2)))) \rrbracket \circ s_D) \\
        &\Vdash \text{(Definition of $\llbracket\rrbracket$, using} \\
        & \;\;\;\;\;\;\;\;\; \text{$(d_1, d_1') = \llbracket \D(t_1) \rrbracket s(x)$ and $(d_2, d_2') = \llbracket \D(t_2) \rrbracket s_D(x)$)}\\
        &S_R(\lambda x. d_1(x) + d_2(x), \lambda x. (d_1(x) + d_2(x), d_1'(x) + d_2'(x))) \\
        &\Vdash \text{(Definition of $S_R$)}\\
        & smooth\ (\lambda x. d_1(x) + d_2(x)) \wedge \\
        & \;\;\; \lambda x. d_1'(x) + d_2'(x) = \sfrac{\partial{(\lambda x. d_1'(x) + d_2'(x))}}{\partial{x}} \\
        &\Vdash \text{(split goals: goal 1)}\\
        &\;\;\;smooth\ (\lambda x. d_1(x) + d_2(x)) \\
        &\;\;\;\Vdash
          \text{(Addition is smooth, if subterms are smooth)}\\
        &\;\;\;smooth\ d_1 \wedge smooth\ d_2 \\
        &\;\;\;\Vdash \text{(Induction hypothesis \ref{eqn:subst_ih_add1} for $d_1$ and \ref{eqn:subst_ih_add2} for $d_2$)}\\
        &\Vdash \text{(split goals: goal 2)}\\
        &\;\;\;\lambda x. d_1'(x) + d_2'(x) = \sfrac{\partial{(\lambda x. d_1'(x) + d_2'(x))}}{\partial{x}} \\
        &\;\;\;\Vdash \text{(By definition of taking the derivative of addition)} \\
        &\;\;\; d_1' = \sfrac{\partial{d_1}}{\partial{x}} \wedge d_2' = \sfrac{\partial{d_2}}{\partial{x}} \\
        &\;\;\;\Vdash \text{(Induction hypothesis \ref{eqn:subst_ih_add1} for $d_1$ and \ref{eqn:subst_ih_add2} for $d_2$)}\\
      \end{align*} \qed

      \item (\<mul>)

      Prove: $S_R(\llbracket mul\ t_1\ t_2 \rrbracket \circ s, \llbracket \D(mul\ t_1\ t_2) \rrbracket \circ s_D)$

      Induction hypotheses:
      \begin{enumerate}
        \item \label{eqn:subst_ih_mul1}$S_R(\llbracket t_1 \rrbracket \circ s, \llbracket \D(t_1) \rrbracket \circ s_D)$
        \item \label{eqn:subst_ih_mul2}$S_R(\llbracket t_2 \rrbracket \circ s, \llbracket \D(t_2) \rrbracket \circ s_D)$
      \end{enumerate}

      Proof goes through almost identically as for the case for \<add>.

      \begin{align*}
        S&_R(\llbracket mul\ t_1\ t_2 \rrbracket \circ s, \llbracket \D(mul\ t_1\ t_2) \rrbracket \circ s_D) \\
        &\Vdash \text{(Definition of $\D$)}\\
        &S_R(\llbracket mul\ t_1\ t_2 \rrbracket \circ s, \llbracket tuple\ \\
        & \;\;\;(mul\ (first\ \D(t_1)) (first\ \D(t_2)))\ \\
        & \;\;\;(add\ \\
        & \;\;\;\;\;(mul\ (first \D(t_1)) (second \D(t_2))) \\
        & \;\;\;\;\;(mul\ (first \D(t_2)) (second \D(t_1)))) \rrbracket \circ s_D) \\
        &\Vdash \text{(Definition of $\llbracket\rrbracket$, using} \\
        & \;\;\;\;\;\;\;\;\; \text{$(d_1, d_1') = \llbracket \D(t_1) \rrbracket s(x)$ and $(d_2, d_2') = \llbracket \D(t_2) \rrbracket s_D(x)$)}\\
        &S_R(\lambda x. d_1(x) * d_2(x), \\
        & \;\;\; \lambda x. (d_1(x) * d_2(x), d_1(x) * d_2'(x) + (d_2(x) * d_1'(x)))) \\
        &\Vdash \text{(Definition of $S_R$)}\\
        &smooth\ (\lambda x. d_1(x) * d_2(x)) \wedge \\
        & \;\;\; \lambda x. d_1(x) * d_2'(x) + d_2(x) * d_1'(x) = \sfrac{\partial{(\lambda x. (d_1(x) * d_2(x))}}{\partial{x}} \\
        &\Vdash \text{(split goals: goal 1)}\\
        &\;\;\;smooth\ (\lambda x. d_1(x) * d_2(x)) \\
        &\;\;\;\Vdash
          \text{(Multiplication is smooth, if subterms are smooth)}\\
        &\;\;\;smooth\ d_1 \wedge smooth\ d_2 \\
        &\;\;\;\Vdash \text{(Induction hypothesis \ref{eqn:subst_ih_mul1} for $d_1$ and \ref{eqn:subst_ih_mul2} for $d_2$)}\\
        &\Vdash \text{(split goals: goal 2)}\\
        &\;\;\;\lambda x. d_1(x) * d_2'(x) + d_2(x) * d_1'(x) = \sfrac{\partial{(\lambda x. (d_1(x) * d_2(x))}}{\partial{x}} \\
        &\;\;\;\Vdash \text{(By definition of taking the derivative of multiplications)} \\
        &\;\;\; d_1' = \sfrac{\partial{d_1}}{\partial{x}} \wedge d_2' = \sfrac{\partial{d_2}}{\partial{x}} \\
        &\;\;\;\Vdash \text{(Induction hypothesis \ref{eqn:subst_ih_mul1} for $d_1$ and \ref{eqn:subst_ih_mul2} for $d_2$)}\\
      \end{align*} \qed

      \item (\<tuple>)

      Prove: $S_(\tau \times \sigma)(\llbracket tuple\ t_1\ t_2 \rrbracket \circ s, \llbracket \D(tuple\ t_1\ t_2) \rrbracket \circ s_D)$

      Induction hypotheses:
      \begin{enumerate}
        \item \label{eqn:subst_ih_tuple1}$S_\tau(\llbracket t_1 \rrbracket \circ s, \llbracket \D(t_1) \rrbracket \circ s_D)$
        \item \label{eqn:subst_ih_tuple2}$S_\sigma(\llbracket t_2 \rrbracket \circ s, \llbracket \D(t_2) \rrbracket \circ s_D)$
      \end{enumerate}

      A recurring pattern will become apparent in later sections when continuing to prove the substitution lemma \ref{thm:substitution_lemma} for types consisting of other types.
      In this case, due to the carefull attention spent on the logical relation, only the witnesses of the subterms of the tuple need to be supplied to finish the proof.

      Note that the witnesses of $S_\tau$ and $S_\sigma$ that need to be given here are supplied by the induction hypotheses.
      While these witnesses are not exactly relevant to finish this proof for \<tuple>, they are needed in the proofs for projections.

      \begin{align*}
        S&_(\tau \times \sigma)(\llbracket tuple\ t_1\ t_2 \rrbracket \circ s, \llbracket \D(tuple\ t_1\ t_2) \rrbracket \circ s_D) \\
        & \Vdash \text{(Definition of $\D$)} \\
        & S_(\tau \times \sigma)(\llbracket tuple\ t_1\ t_2 \rrbracket \circ s, \llbracket tuple\ \D(t_1)\ \D(t_2)) \rrbracket \circ s_D) \\
        & \Vdash \text{(Definition of $\llbracket\rrbracket$)} \\
        & S_(\tau \times \sigma)(\lambda x. (\llbracket t_1 \rrbracket(s(x)), \llbracket t_2 \rrbracket(s(x))), \\
        & \;\;\;\;\;\;\lambda x. (\llbracket \D(t_1) \rrbracket(s'(x)), \llbracket \D(t_2) \rrbracket(s'(x)))) \\
        & \Vdash \text{(Definition of $S_{\tau\times\sigma}$)} \\
        & \exists f_1, f_2, g_1, g_2, \\
            & \;\;\;\;S_\tau(f_1, f_2), S_\sigma(g_1, g_2). \\
            & \;\;\;\;\lambda x. (\llbracket t_1 \rrbracket(s(x)), \llbracket t_2 \rrbracket(s(x))) = \lambda x. (f_1(x), g_1(x)) \wedge \\
            & \;\;\;\;\lambda x. (\llbracket \D(t_1) \rrbracket(s'(x)), \llbracket \D(t_2) \rrbracket(s'(x))) = \lambda x. (f_2(x), g_2(x)) \\
        & \Vdash \text{(Give witnesses: $f_1 := \llbracket t_1 \rrbracket \circ s$, $f_2 := \llbracket t_2 \rrbracket \circ s$,} \\
        & \;\;\;\;\;\; \text{$g_1 := \llbracket \D(t_1) \rrbracket \circ s'$, $g_2 := \llbracket \D(t_2) \rrbracket \circ s'$)} \\
        & \exists S_\tau(f_1, f_2), S_\sigma(g_1, g_2). \\
          & \;\;\;\;\lambda x. (\llbracket t_1 \rrbracket(s(x)), \llbracket t_2 \rrbracket(s(x))) \\
          & \;\;\;\;\;\;\; = \lambda x. (\llbracket t_1 \rrbracket(s(x)), \llbracket t_2 \rrbracket(s(x))) \wedge \\
          & \;\;\;\;\lambda x. (\llbracket \D(t_1) \rrbracket(s'(x)), \llbracket \D(t_2) \rrbracket(s'(x))) \\
          & \;\;\;\;\;\;\; = \lambda x. (\llbracket \D(t_1) \rrbracket(s'(x)), \llbracket \D(t_2) \rrbracket(s'(x))) \\
        & \Vdash \text{(Give witnesses of $S_\tau$ and $S_\sigma$ using respective IHs \ref{eqn:subst_ih_tuple1} and \ref{eqn:subst_ih_tuple2})} \\
        & \;\;\;\;\lambda x. (\llbracket t_1 \rrbracket(s(x)), \llbracket t_2 \rrbracket(s(x))) \\
        & \;\;\;\;\;\;\; = \lambda x. (\llbracket t_1 \rrbracket(s(x)), \llbracket t_2 \rrbracket(s(x))) \wedge \\
        & \;\;\;\;\lambda x. (\llbracket \D(t_1) \rrbracket(s'(x)), \llbracket \D(t_2) \rrbracket(s'(x))) \\
        & \;\;\;\;\;\;\; = \lambda x. (\llbracket \D(t_1) \rrbracket(s'(x)), \llbracket \D(t_2) \rrbracket(s'(x))) \\
        & \Vdash \text{(Reflexivity)} \\
      \end{align*}\qed
      \item (\<first>)

      Prove: $S_(\tau)(\llbracket first\ t \rrbracket \circ s, \llbracket \D(first\ t) \rrbracket \circ s_D)$

      Induction hypotheses:
      \begin{enumerate}
        \item \label{eqn:subst_ih_first}$S_{\tau\times\sigma}(\llbracket t \rrbracket \circ s, \llbracket \D(t) \rrbracket \circ s_D)$
      \end{enumerate}

      Simplifying the induction hypothesis \ref{eqn:subst_ih_first} using the definition of $S_{\tau\times\sigma}$ gives rise to a number of useful assumptions containing:
      $f_1 : R \rightarrow \llbracket \tau \rrbracket$
      , $f_2 : R \rightarrow \llbracket \D(\tau) \rrbracket$
      , $g_1 : R \rightarrow \llbracket \sigma \rrbracket$
      and $g_2 : R \rightarrow \llbracket \D(\sigma) \rrbracket$.

      Assumptions:
      \begin{enumerate}
        \item \label{eqn:subst_ass_proj1_4} $S_\tau(f_1, f_2)$
        \item \label{eqn:subst_ass_proj1_5} $S_\sigma(g_1, g_2)$
        \item \label{eqn:subst_ass_proj1_6} $\llbracket t \rrbracket \circ s = \lambda x. (f_1(x), g_1(x))$
        \item \label{eqn:subst_ass_proj1_7} $\llbracket \D(t) \rrbracket \circ s = \lambda x. (f_2(x), g_2(x))$
      \end{enumerate}

      \begin{align*}
        S&_{\tau}(\llbracket first\ t \rrbracket \circ s, \llbracket \D(first\ t) \rrbracket \circ s_D) \\
        & \Vdash \text{(Rewrite using definition of $\D$)} \\
        & S_{\tau}(\llbracket first\ t \rrbracket \circ s, \llbracket first\ \D(t) \rrbracket \circ s_D) \\
        & \Vdash \text{(Rewrite using definition of $\llbracket\rrbracket$)} \\
        & S_{\tau}(\lambda x. fst(\llbracket t \rrbracket(s(x))), \lambda x. fst(\llbracket \D(t) \rrbracket(s_D(x)))) \\
        & \Vdash \text{(Rewrite using \ref{eqn:subst_ass_proj1_6} and \ref{eqn:subst_ass_proj1_7})} \\
        & S_{\tau}(\lambda x. fst(f_1(x), g_1(x)), \lambda x. fst(f_2(x), g_2(x))) \\
        & \Vdash \text{($\beta\eta$-equality)} \\
        & S_{\tau}(f_1, f_2) \\
        & \Vdash \text{(Assumption \ref{eqn:subst_ass_proj1_4})} \\
      \end{align*} \qed

      \item (\<second>)

      Prove: $S_(\tau)(\llbracket first\ t \rrbracket \circ s, \llbracket \D(first\ t) \rrbracket \circ s_D)$

      Induction hypotheses:
      \begin{enumerate}
        \item \label{eqn:subst_ih_first}$S_{\tau\times\sigma}(\llbracket t \rrbracket \circ s, \llbracket \D(t) \rrbracket \circ s_D)$
      \end{enumerate}

      Proof goes the same as the case for \<first> with the same assumptions following from the induction hypothesis, with
      $f_1 : R \rightarrow \llbracket \tau \rrbracket$
      , $f_2 : R \rightarrow \llbracket \D(\tau) \rrbracket$
      , $g_1 : R \rightarrow \llbracket \sigma \rrbracket$
      and $g_2 : R \rightarrow \llbracket \D(\sigma) \rrbracket$.

      Assumptions:
      \begin{enumerate}
        \item \label{eqn:subst_ass_proj2_4} $S_\tau(f_1, f_2)$
        \item \label{eqn:subst_ass_proj2_5} $S_\sigma(g_1, g_2)$
        \item \label{eqn:subst_ass_proj2_6} $\llbracket t \rrbracket \circ s = \lambda x. (f_1(x), g_1(x))$
        \item \label{eqn:subst_ass_proj2_7} $\llbracket \D(t) \rrbracket \circ s = \lambda x. (f_2(x), g_2(x))$
      \end{enumerate}

      \begin{align*}
        S&_{\sigma}(\llbracket second\ t \rrbracket \circ s, \llbracket \D(second\ t) \rrbracket \circ s_D) \\
        & \Vdash \text{(Rewrite using definition of $\D$)} \\
        & S_{\sigma}(\llbracket second\ t \rrbracket \circ s, \llbracket second\ \D(t) \rrbracket \circ s_D) \\
        & \Vdash \text{(Rewrite using definition of $\llbracket\rrbracket$)} \\
        & S_{\sigma}(\lambda x. snd(\llbracket t \rrbracket(s(x))), \lambda x. snd(\llbracket \D(t) \rrbracket(s_D(x)))) \\
        & \Vdash \text{(Rewrite using \ref{eqn:subst_ass_proj2_6} and \ref{eqn:subst_ass_proj2_7})} \\
        & S_{\sigma}(\lambda x. snd(f_1(x), g_1(x)), \lambda x. snd(f_2(x), g_2(x))) \\
        & \Vdash \text{($\beta\eta$-equality)} \\
        & S_{\sigma}(f_1, f_2) \\
        & \Vdash \text{(Assumption \ref{eqn:subst_ass_proj2_4})} \\
      \end{align*} \qed
    \end{enumerate}
  \end{proof}

  The proof of the fundamental property of the logical relation now follows from the substitution lemma.

  \begin{lemma}[Fundamental property]\label{thm:fundamental_property}
    For any well-typed term $x_1 : R, \dots, x_n : R \vdash t : \tau$, and argument function $f : R \rightarrow \llbracket R^n \rrbracket$, such that each argument is continuously derivable, then $S_\tau(\llbracket t\rrbracket \circ f, \llbracket \D(t)\rrbracket \circ \D_n \circ f)$.
  \end{lemma}

  \begin{proof}
    This is proven by instantiating the substitution lemma \ref{thm:substitution_lemma} with the proper variables and proving the resulting judgement of $inst_{R^n}$ by induction on $n$.

    \begin{align*}
      S&_{\tau}(\llbracket t \rrbracket \circ f, \llbracket \D(t) \rrbracket \circ \D_n \circ f) \\
      & \Vdash \text{(Apply substitution lemma with $s := f$, $s_D := \D_n \circ f$ and $\Gamma := R^n$)} \\
      & inst_{R^n}(f, \D_n \circ f) \\
    \end{align*}

    Proceed by induction on $n$, intuitively building up the environment with denotation of terms such that they follow $S$.

    \begin{itemize}
      \item Base case: $n = 0$

      \begin{align*}
        inst&_{R^0}(f, \D_0 \circ f) \\
        & \Vdash \text{(Induction on n, base case $n = 0$)} \\
        & \;\;\; inst_{[]}(f, \D_0 \circ f) \\
        & \;\;\; \Vdash \text{(Singleton instance of $R \rightarrow R^0$, $f = const([])$)} \\
        & \;\;\; inst_{[]}(const([]), \D_0 \circ const([])) \\
        & \;\;\; \Vdash \text{(Definition of $\D_0$)} \\
        & \;\;\; inst_{[]}(const([]), const([])) \\
        & \;\;\; \Vdash \text{(Definition of $inst_{[]}$)}
      \end{align*}

      \item Induction case: $n = S(n')$

      Induction hypothesis: $inst_{R^{n'}}(f', D \circ f')$, where
        $f' : R \rightarrow \llbracket R^{n'}\rrbracket$.

      \begin{align*}
        inst&_{R :: R^{n'}}(f, \D_{R :: R^{n'}} \circ f) \\
        & \;\;\; \Vdash \text{(Unfold $\circ$)} \\
        & \;\;\; inst_{R :: R^{n'}}(\lambda x. f(x), \lambda x. \D_{R :: R^{n'}}( f, x)) \\
        & \;\;\; \Vdash \text{(Rewrite using $f = \lambda x. hd(f(x)) :: tl(f(x))$} \\
        & \;\;\;\;\;\;\;\;\;\;\;\; \text{and definition of $\D_{R :: R^{n'}}$)} \\
        & \;\;\; inst_{R :: R^{n'}}(\lambda x. hd(f(x)) :: tl(f(x)), \\
        & \;\;\;\;\;\;
          \lambda x. (hd(f(x)), \sfrac{\partial{(hd \circ f)}}{\partial{x}}(x)) :: \D_{R^{n'}}(tl \circ f, x)) \\
        & \;\;\; \Vdash \text{(By definition of $inst_{R :: R^{n'}}$, rest proven by IH)}
      \end{align*}
    \end{itemize}
  \end{proof}

  Note that the correctness of the macro is dependent on the requirement that the denotations supplied by the argument function are all continuously derivable.

  \begin{theorem}[Macro correctness]
    For any term $x_1 : R, ..., x_n : R \vdash t : R$, $\llbracket\D(t)\rrbracket$ gives the dual number representation of $\llbracket t \rrbracket$, such that for any argument function $f : R \rightarrow R^n$, then $\llbracket \D(t) \rrbracket \circ \D_n \circ f = \lambda x. (\llbracket t \rrbracket \circ f, \sfrac{\partial{(\llbracket t \rrbracket \circ f)}}{\partial{x}})$.
  \end{theorem}

  \begin{proof}
    This is proven by showing that the goal follows from the logical relation which itself implied by the fundamental property (\ref{thm:fundamental_property}) for well-typed terms.

    \begin{align*}
      \llbracket \D(t) &\rrbracket \circ \D_n \circ f = \lambda x. (\llbracket t \rrbracket \circ f, \sfrac{\partial{(\llbracket t \rrbracket \circ f)}}{\partial{x}}) \\
      & \Vdash \text{(By definition of $S_R$ with $f := \llbracket t \rrbracket \circ f$ and $g := \llbracket \D(t) \rrbracket \circ \D_n \circ f$)} \\
      & S_R(\llbracket t \rrbracket \circ f, \llbracket \D(t) \rrbracket \circ \D_n \circ f) \\
      & \Vdash \text{(Fundamental property (\ref{thm:fundamental_property}))}
    \end{align*}
  \end{proof}

  \subsection{Adding Sums and Primitive Recursion}
    Now that correctness has been verified for the base simply-typed lambda calculus, the next goal will be to add in both sum and integer types.
    The inference rules for the language constructs added for sum types are given in figure \ref{}

    \begin{figure}[H]
      $\dots$
      \begin{mathpar}
        \inferrule*[Right=\textsc{TCase}]
          {\Gamma \vdash e : \tau + \sigma \\
            \Gamma \vdash t1 : \tau \rightarrow \rho \\
            \Gamma \vdash t2 : \sigma \rightarrow \rho }
          {\Gamma \vdash \case{e}{t1}{t2} : \rho} \\ \and
        \inferrule*[Right=\textsc{TInl}]
          {\Gamma \vdash t : \tau}
          {\Gamma \vdash \inl{t} : \tau + \sigma} \and
        \inferrule*[Right=\textsc{TInr}]
          {\Gamma \vdash t : \sigma}
          {\Gamma \vdash \inr{t} : \tau + \sigma}
      \end{mathpar}
      \caption{Type-inferrence rules for language constructs for sum types}
      \label{fig:base_infer}
    \end{figure}

  \subsection{Arrays}
\section{Optimization}
  \subsection{Program Transformations}
\section{Reverse-Mode AD}
\section{Discussion}
  \subsection{Problems}
  \subsection{Future Work}
\section{Conclusion}

\appendix
\section{Language Definitions}
\section{Forward-Mode Macro}
\section{Denotations}
\printbibliography
\makeatother
\end{document}