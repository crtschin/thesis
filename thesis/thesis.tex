\documentclass[11pt, final]{article}
\usepackage{mystyle}

\addbibresource{./references.bib}

\input{definitions.tex}

\setlength{\headheight}{15pt}
\pagestyle{fancy}
\lhead{Utrecht University}
\rfoot{\thepage}
\cfoot{ }
\allowdisplaybreaks

\begin{document}

\input{titlepage.tex}
\newpage

\input{abstract.tex}
\newpage

\pagenumbering{arabic}
\setcounter{page}{3}
\tableofcontents
\newpage

\input{introduction}

\section{Background}

\input{ad.tex}
\input{denotational.tex}
\input{coq.tex}
\input{logical_relation.tex}
\input{related_work.tex}

\section{Formalizing Forward-Mode AD}
  The formalization of the forward-mode automatic differentiation macro will be explained in the following sections.
  The formal proof will start from a base simply-typed lambda calculus enriched with product types and incrementally add both sum and array types.
  Also included in the final language is an implementation of primitive recursion using integer types.
  Many of the theorems and lemmas will stay consistent between sections as the overarching correctness statement does not change.
  Later section only add their respective cases to the corresponding proofs of the lemmas.

  \subsection{Simply Typed Lambda Calculus}\label{sec:formal_stlc}
  % Talk about simply typed lambda calculus,
  % Something about Λ_δ^{+, *, R}
  % Give examples of functions
  % talk about denotations and
  As mentioned in background section~\ref{sec:language_repr}, we will make use of De-Bruijn indices in a intrinsic representation to formulate our language.
  Both addition and multiplication are included as operations on the real numbers.
  Our base language consists of the simply-typed lambda calculus with product types and real numbers, hereby referenced as $\Lambda_{\delta}^{\times, \rightarrow, R}$, where $\delta$ consists of the addition and multiplication operators.

  Both the language constructs and the typing rules for this language are standard for a simply typed lambda calculus, as shown in \ref{fig:base_infer}.
  As expected we include variables, applications and abstractions in the \<var>, \<app> and \<abs> constructors.
  Product types are added to the language in the form of binary projections, \<first> and \<second> to represent respectively the left and right projections of \<tuple> terms.
  For real numbers, \<rval> is used to introduce real numbered constants and \<add> and \<mul> will be used to respectively encode addition and multiplication.

  \begin{figure}
    \begin{mathpar}
      \inferrule*[Right=\textsc{TVar}]
        {elem\ n\ \Gamma = \tau}
        {\Gamma \vdash \var{n} : \tau} \and
      \inferrule*[Right=\textsc{TAbs}]
        {(\sigma, \Gamma) \vdash t : \tau}
        {\Gamma \vdash \abs{t} : \sigma \rightarrow \tau} \\ \and
      \inferrule*[Right=\textsc{TApp}]
        {\Gamma \vdash t1 : \sigma \rightarrow \tau \\
          \Gamma \vdash t2 : \sigma}
        {\Gamma \vdash \app{t1}{t2} : \tau} \\ \and
      \inferrule*[Right=\textsc{TTuple}]
        {\Gamma \vdash t1 : \tau \\
          \Gamma \vdash t2 : \sigma}
        {\Gamma \vdash \tuple{t1}{t2} : \tau \times \sigma} \\ \and
      \inferrule*[Right=\textsc{TFst}]
        {\Gamma \vdash t : \tau \times \sigma}
        {\Gamma \vdash \first{t} : \tau} \and
      \inferrule*[Right=\textsc{TSnd}]
        {\Gamma \vdash t : \tau \times \sigma}
        {\Gamma \vdash \second{t} : \sigma} \\ \and
      \inferrule*[Right=\textsc{TRVal}]
        {r \in \denoteR}
        {\Gamma \vdash \rval{r} : \<R>} \\ \and
      \inferrule*[Right=\textsc{TAdd}]
        {\Gamma \vdash r1 : \<R> \\
          \Gamma \vdash r2 : \<R> \\ }
        {\Gamma \vdash \add{r1}{r2} : \<R>} \and
      \inferrule*[Right=\textsc{TMull}]
        {\Gamma \vdash r1 : \<R> \\
        \Gamma \vdash r2 : \<R> \\ }
      {\Gamma \vdash \mul{r1}{r2} : \<R>} \and
    \end{mathpar}
    \caption{Type-inference rules for the base simply-typed lambda calculus}
    \label{fig:base_infer}
  \end{figure}

  % How we translated this into the well-typed intrinsic representation
  These can be translated into Coq definitions in a reasonably straightforward manner, with each case keeping track of both how the typing context and types change.
  In the \<var> case we need some way to determine what type the variable is referencing.
  Like many others previously\cite{Benton2011}\cite{Coquand1994}, instead of using indices into the list accompanied with a proof that the index does not exceed the length of the list, we make use of an inductively defined type evidence to type our variables as shown in \ref{lst:strong_stlc}.
  The cases for \<app> and \<abs> are as expected, where variables in the body of abstraction are able to reference their respective arguments.

  Notably, in the original proof by Huot, Staton, and \Vakar{} \cite{huot2020correctness}, they make use of n-ary products accompanied with pattern matching expressions.
  We opted to implement binary projection products, as they are conceptually simpler while still retaining much of the same functionality expected of product types.

  \begin{minted}{coq}
    Inductive tm ~(\Gamma : Ctx) : ty \rightarrow Type~ :=
      ...
      (* Binary projection products *)
      | tuple : ~forall {\tau \sigma},
        tm \Gamma \tau \rightarrow
        tm \Gamma \sigma \rightarrow
        tm \Gamma (\tau \times \sigma)~
      | first : ~forall {\tau \sigma}, tm \Gamma (\tau \times \sigma) \rightarrow tm \Gamma \tau~
      | second : ~forall {\tau \sigma}, tm \Gamma (\tau \times \sigma) \rightarrow tm \Gamma \sigma~
      ...
  \end{minted}

  % \begin{listing}
  %   \begin{minted}{coq}
  % Definition Ctx : Type := list ty.

  % Inductive tm ~(\Gamma : Ctx) : ty \rightarrow Type~ :=
  %   (* Base STLC *)
  %   | var : ~forall \tau,
  %     \tau ∈ \Gamma \rightarrow tm \Gamma \tau~
  %   | app : ~forall \tau \sigma,
  %     tm \Gamma (\sigma \Rightarrow \tau) \rightarrow
  %     tm \Gamma \sigma \rightarrow
  %     tm \Gamma \tau~
  %   | abs : ~forall \tau \sigma,
  %     tm (\sigma::\Gamma) \tau \rightarrow tm \Gamma (\sigma \Rightarrow \tau)~

  %   (* Operations on real numbers *)
  %   | const : ~R \rightarrow tm \Gamma Real~
  %   | add : ~tm \Gamma Real \rightarrow tm \Gamma Real \rightarrow tm \Gamma Real~
  %   | mul : ~tm \Gamma Real \rightarrow tm \Gamma Real \rightarrow tm \Gamma Real~

  %   (* Binary projection products *)
  %   | tuple : ~forall {\tau \sigma},
  %     tm \Gamma \tau \rightarrow
  %     tm \Gamma \sigma \rightarrow
  %     tm \Gamma (\tau \times \sigma)~
  %   | first : ~forall {\tau \sigma}, tm \Gamma (\tau \times \sigma) \rightarrow tm \Gamma \tau~
  %   | second : ~forall {\tau \sigma}, tm \Gamma (\tau \times \sigma) \rightarrow tm \Gamma \sigma~
  %   \end{minted}
  %   \caption{\<Coq> definition of the base lambda calculus}
  %   \label{lst:stlc_base}
  % \end{listing}

  We use the same inductively defined macro on types and terms used by many previous authors to implement the forward-mode automatic differentiation macro\cite{huot2020correctness}\cite{barthe2020versatility}\cite{Shaikha2019}.
  The forward-mode macro, $\D$, keeps track of both primal and tangent traces using tuples as respectively its first and second elements.
  In most cases, the macro simply preserves the structure of the language.
  The cases for real numbers such as addition and multiplication are the exception.
  Here, the element encoding the tangent trace needs to contain the proper syntactic translation of the derivative of the operation.

  \begin{figure}[H]
    \centering
    \begin{equation*}
      \begin{split}
        \D(\<R>) &= \<R> \times \<R> \\
        \D(\tau \times \sigma) &= \D(\tau) \times \D(\sigma) \\
        \D(\tau \rightarrow \sigma) &= \D(\tau) \rightarrow \D(\sigma)
      \end{split}
      \begin{split}
        \D(\rval{n}) &= \tuple{(\rval{n})}{(\rval{0})} \\
        \D(\add{n}{m}) &= \tuple{(\add{n}{m})}{(\add{n'}{m'})} \\
        \D(\mul{n}{m}) &= \tuple{(\mul{n}{m})} \\
          &{(\add{(\mul{n'}{m})}{(\mul{m'}{n})})})
      \end{split}
    \end{equation*}
    \caption{Macro on base simply-typed lambda calculus}
    \label{eqn:macro_base}
  \end{figure}

  This is implemented by destructing the recursive calls to $\<D>$ to access the syntactic counterparts of the primal and tangent denotations.
  Note that applying the macro to variables do nothing exceptional as the macro is also applied to the typing context, so variables implicitly already reference macro-applied terms.

  Due to restricting our language to be total and excluding constructs related to partiality such as general recursion and iteration, it suffices to give our language a set-theoretic denotational semantics.
  Like the type evidences, well-typed terms will denotate to functions $\llbracket \Gamma \rrbracket \rightarrow \llbracket \tau \rrbracket$.

  \begin{figure}
    \centering
    \begin{equation*}
      \begin{split}
        \llbracket \<R> \rrbracket &= \<denoteR> \\
        \llbracket \tau \times \sigma \rrbracket &=
          \llbracket \tau \rrbracket * \llbracket \sigma \rrbracket \\
        \llbracket \tau \rightarrow \sigma \rrbracket &= \llbracket \tau \rrbracket \rightarrow \llbracket \sigma \rrbracket \\
        \\
        \llbracket \<Top> \rrbracket &= \<hd> \\
        \llbracket \<Pop>\ v \rrbracket &= \<tl> \circ \llbracket v \rrbracket \\
      \end{split}
      \;\;\;
      \begin{split}
        \llbracket \var{v} \rrbracket &=
          \lambda x. lookup\ \llbracket v \rrbracket\ x \\
        \llbracket \app{t_1}{t_2} \rrbracket &=
          \lambda x. (\llbracket t_1 \rrbracket(x)) (\llbracket t_2 \rrbracket(x)) \\
        \llbracket \abs{t} \rrbracket &=
          \lambda x\ y. \llbracket t \rrbracket(y :: x) \\
        \llbracket \add{t_1}{t_2} \rrbracket &=
          \lambda x. \llbracket t_1 \rrbracket(x) + \llbracket t_2 \rrbracket(x) \\
        \llbracket \mul{t_1}{t_2} \rrbracket &=
          \lambda x. \llbracket t_1 \rrbracket(x) * \llbracket t_2 \rrbracket(x) \\
        \llbracket \tuple{t_1}{t_2} \rrbracket &=
          \lambda x. (\llbracket t_1 \rrbracket(x), \llbracket t_2 \rrbracket(x)) \\
        \llbracket \first{t} \rrbracket &=
          \lambda x. let\ (x, y) = \llbracket t \rrbracket(x)\ in\ x \\
        \llbracket \second{t} \rrbracket &=
          \lambda x. let\ (x, y) = \llbracket t \rrbracket(x)\ in\ y \\
      \end{split}
    \end{equation*}
    \caption{Denotations of the base simply-typed lambda calculus}
    \label{eqn:lr_base}
  \end{figure}

  For any type $\tau$, simply swap out the syntactic type to its corresponding \<Coq> variant in \<Type>.
  So the syntactic \<R> will denotate to the $\<denoteR>$ type in \<Coq>.
  Denotating the terms in our language now corresponds to finding the appropriate inhabitants in the denotated types.
  We denotate our typing contexts $\Gamma$, lists of types, as heterogeneous lists containing their corresponding denotations.
  The specific implementation of heterogeneous lists used, correspond to the one given by Adam Chlipala\cite{ChlipalaCPDT}.

  When working through giving the constructs in our language the proper denotations, most of the cases are straightforward.
  Notable is the case for variables, where we made use of an inductively defined evidence to type our terms.
  As denotations, these evidences wil correspond to lookups into our heterogeneous lists to their appropriate types.

  % \begin{listing}
  %   \begin{minted}{coq}
  %   \end{minted}
  %   \caption{Denotatonal semantics for types, typing contexts and lookups.}
  %   \label{lst:denotation_types}
  % \end{listing}

  % \begin{listing}
  %   \begin{minted}{coq}
  %   \end{minted}
  %   \caption{Denotatonal semantics for the base simply-typed lambda calculus.}
  %   \label{lst:denotation_base}
  % \end{listing}

  % In the section denotation
  % Explain expressiveness of base language
  % Work out examples
  As mentioned by by Barthe, et. al.\cite{barthe2020versatility}, this small calculus, $\lambdaBase$, accompanied with the arguably simple set-theoretic denotational semantics is expressive enough to encode the higher-order polynomials containing the addition and multiplication operators.

  \begin{example}[Square]
    $abs\ (mul\ (var\ Top)\ (var\ Top))$ denotates to the square function $\lambda x. x * x$.
    \begin{proof}
      This follows from the definition of our denotation functions.
      \begin{align*}
        \llbracket abs\ &(mul\ (var\ Top)\ (var\ Top)) \rrbracket\ [] \\
          &\equiv \lambda x.
            \llbracket mul\ (var\ Top)\ (var\ Top) \rrbracket\ [x] \\
          &\equiv \lambda x.
            \llbracket var\ Top \rrbracket\ [x] *
              \llbracket var\ Top \rrbracket\ [x] \\
          &\equiv \lambda x. x * x \qedhere
      \end{align*}
    \end{proof}
  \end{example}

  % TODO: give reasonable examples

  As we work with denotations, smooth functions $f : \<R>^n -> \<R>$ can be interpreted as the denotations of a corresponding syntactic term $x_1, \dots, x_n \vdash t : R$.
  Intuitively, the free variables in the term $t$ denote the usages of the parameters of the function and as such are restricted to terms of type $R$, same as each of the arguments in the function $f$.
  Note that while both the arguments and result type of $t$ are restricted to $R$, $t$ itself can consist of higher order types.

  Although Barthe, et. al.\cite{barthe2020versatility} gave a syntactic proof of correctness of the macro, our proof follows the more denotational style of proof given by Huot, Staton and \Vakar{}\cite{huot2020correctness}.
  Correctness of the forward-mode macro consists of the assertion that the denotation of any macro-applied term of type $x_1 : R, \dots, x_n : R \vdash t : \<R>$ will result in a pair of both the denotation of the original term and the derivative of that denotation.

  Likewise, the proof of correctness will follow a logical relations argument, first generalizing the statement for both the typing contexts and the result type.
  The relation will ensure that both the derivability property and the derivatives are preserved over higher-order types.
  We define the logical relation as a type-indexed relation between denotations of both terms and their macro-applied variants, so for any type $\tau$, $S_\tau$ is the relation between functions $R \rightarrow \llbracket \tau \rrbracket$ and $R \rightarrow \llbracket \D(\tau) \rrbracket$.

  \begin{equation}
    S_\tau(f, g) =
      \left\{
        \begin{array}{ll}
          smooth\ f \wedge
            g = \lambda x. (f(x), \frac{\partial f}{\partial x}(x))
            & : \tau = R \\
          \exists f_1, f_2, g_1, g_2,
            & : \tau = \sigma \times \rho \\
            \;\;\;\;S_\sigma(f_1, f_2), S_\sigma(g_1, g_2). \\
            \;\;\;\;f = \lambda x. (f_1(x), g_1(x)) \wedge \\
            \;\;\;\;g = \lambda x. (f_2(x), g_2(x)) \\
          \forall f_1, f_2.
            & : \tau = \sigma \rightarrow \rho \\
            \;\;\;\;S_\sigma(f_1, f_2) \Rightarrow \\
            \;\;\;\;S_\rho(\lambda x. f(x)(f_1(x)),\lambda x. f(x)(f_2(x)))
        \end{array}
      \right.
  \label{eqn:lr_base}
  \end{equation}

  The next step involves proving that syntactically well-typed terms are semantically correct.
  In other words, the relation needs to be proven valid for any term $x_1 : R, \dots, x_n : R \vdash t : \tau$ and argument function $f : R \rightarrow R^n$ such that $S_\tau(\llbracket t \rrbracket \circ f, \llbracket \D(t) \rrbracket \circ \D_n \circ f)$.

  To properly instantiate the arguments to the denotation of the macro-applied term, an auxiliary function is needed that pairs each constant with their derivative $0$. So it transforms $f : R \rightarrow \llbracket R^n \rrbracket$ into $\D_n(f, x) : R \rightarrow \llbracket \D(R)^n \rrbracket$.
  The full type signature of the function becomes $\D_n : (R \rightarrow \llbracket R^n \rrbracket) \rightarrow R \rightarrow \llbracket \D(R)^n \rrbracket$, which essentially accompanies each argument supplied by $f$ with its accompanying derivative.

  \begin{equation}
    \D_n(f, x) =
      \left\{
        \begin{array}{ll}
          f(x) & : n = 0 \\
          ((hd \circ f)(x)), \frac{\partial{(hd \circ f)}}{\partial{x}}(x)) :: \D_{n'}(tl \circ f, x) & : n = S(n') \\
        \end{array}
      \right.
  \label{eqn:argument_df}
  \end{equation}

  Proving this statement directly by induction on the typing derivation, however, does not work.
  As expected in a logical relations proof, the indicative issue lies in both the case for applications and abstractions.
  To make this work, the correctness statement needs to be generalized to arbitrary contexts and implicitly, substitutions.

  If this were a syntactic proof, one would need to show that relation is preserved when applying substitutions consisting of arbitrary terms, possibly containing higher-order constructs.
  In this style of proof, the same concept needs to be incorporated in the argument function $f$, which intuitively speaking, supplies the terms referenced by variables through the typing context.

  % TODO: attempt to do this?

  To prove this statement, it first needs to be generalized to arbitrary substitutions.
  The key in formulating these denotationally lies in what was previously the argument function $f : R \rightarrow R^n$.
  Previously the function was used to indicate the open variables or function arguments.
  If generalized to $\Gamma = x_1 : \tau_1, \dots, x_n : \tau_n$, this same function could be seen as a function which supplies terms foreach open variable $x_1, \dots, x_n$ with their appropriate types.
  So the argument function now becomes the pair of functions $s : R \rightarrow \llbracket \Gamma \rrbracket$ and $s_D : R \rightarrow \llbracket \D(\Gamma) \rrbracket$.
  Note that the functions $s$ and $s_D$ are built out of the denotations of terms such that these same denotations follow the logical relation (\ref{eqn:lr_base}) for our language.
  We phrase this requirement as a definition.

  \begin{definition}(Instantiation)
    Substitutional functions $s : R \rightarrow \llbracket \Gamma \rrbracket$ and $s_D : R \rightarrow \llbracket \D(\Gamma) \rrbracket$ are inductively instantiated such that they follow
    \begin{equation}
      inst_\Gamma(f, g) =
        \left\{
          \begin{array}{ll}
            f = const([]) \wedge g = const([])
              & : \Gamma = [] \\
            \forall f_1, f_2, g_1, g_2.
              & : \Gamma = (\tau :: \Gamma') \\
              \;\;inst_{\Gamma'}(f_1, g_1) \wedge S_\tau(f_2, g_2) \\
              \;\;\;\; \implies f = \lambda x. (f_2(x) :: f_1(x)) \wedge \\
              \;\;\;\;\;\; g = \lambda x. (g_2(x) :: g_1(x))
          \end{array}
        \right.
    \label{eqn:lr_base}
    \end{equation}
  \end{definition}

  Using this notion of substitution instantiations we can now formulate our substitution lemma.

  \begin{lemma}[Substitution]\label{thm:substitution_lemma}
    For any well-typed term $\Gamma \vdash t : \tau$, and instantiation functions $s : R \rightarrow \llbracket \Gamma \rrbracket$ and $s_D : R \rightarrow \llbracket \D(\Gamma) \rrbracket$ such that they follow $inst_\Gamma(s, s_D)$, then $S_\tau(\llbracket t\rrbracket \circ s, \llbracket \D(t)\rrbracket \circ s_D)$.
  \end{lemma}

  The proof proceeds by induction on the typing derivation of the well-typed term $t$.
  The majority of cases follow from the induction hypothesis.
  The case for \<var> follows from $inst$ which ensures that any term referenced is semantically well-typed with respect to the relation.
  Proving the cases used to encode the operators on reals such as \<add> and \<mul> involve proving both smoothness and giving the witness of the derivative.

  % \input{proof_base.tex}

  We can derive the fundamental property of the base logical relation directly from the substitution lemma.
  This involves proving the prerequisite $inst$ we used previously.
  Note that the correctness of both the macro and the fundamental property is dependent on the requirement that the denotations supplied by the argument function are smooth.

  \begin{lemma}[Fundamental property]\label{thm:fundamental_property}
    For any term $x_1 : R, ..., x_n : R \vdash t : R$, $\llbracket\D(t)\rrbracket$ gives the dual number representation of $\llbracket t \rrbracket$, such that for any argument function $f : R \rightarrow R^n$, then $S_\tau(\llbracket t\rrbracket \circ f, \llbracket \D(t)\rrbracket \circ \D_n \circ f)$.
  \end{lemma}

  This is proven by the substitution lemma.
  The remaining goal of $inst_{R^n}$ is proven by induction on $n$, the number of arguments.
  With the case where $n = 0$, the goal is trivial due to the argument function $f$ being extensionally equal to $const\ []$, which directly corresponds to $inst_{[]}$.
  Similarly the induction step is proven by both the induction hypothesis and the assumption that the denotations of the arguments supplied are smooth.


  \begin{theorem}[Macro correctness]
    For any term $x_1 : R, ..., x_n : R \vdash t : R$, $\llbracket\D(t)\rrbracket$ gives the dual number representation of $\llbracket t \rrbracket$, such that for any argument function $f : R \rightarrow R^n$, then $\llbracket \D(t) \rrbracket \circ \D_n \circ f = \lambda x. (\llbracket t \rrbracket \circ f, \sfrac{\partial{(\llbracket t \rrbracket \circ f)}}{\partial{x}})$.
  \end{theorem}

  \begin{proof}
    This is proven by showing that the goal follows from the logical relation which itself implied by the fundamental property (\ref{thm:fundamental_property}) for well-typed terms.

    \begin{align*}
      \llbracket \D(t) &\rrbracket \circ \D_n \circ f = \lambda x. (\llbracket t \rrbracket \circ f, \sfrac{\partial{(\llbracket t \rrbracket \circ f)}}{\partial{x}}) \\
      & \Vdash \text{(By definition of $S_R$ with $f := \llbracket t \rrbracket \circ f$ and $g := \llbracket \D(t) \rrbracket \circ \D_n \circ f$)} \\
      & S_R(\llbracket t \rrbracket \circ f, \llbracket \D(t) \rrbracket \circ \D_n \circ f) \\
      & \Vdash \text{(Fundamental property (\ref{thm:fundamental_property}))}
    \end{align*}
  \end{proof}

  \subsection{Adding Sums and Primitive Recursion}
    Now that correctness has been verified for the base simply-typed lambda calculus, the next goal will be to add in both sum and integer types.
    In the interest of testing the flexibility of both the representation and the proofing technique, integer types and primitive recursion were also added.
    The inference rules for the new language constructs added for sum and number types are given in figure \ref{fig:sum_prim_infer}

    \begin{figure}[H]
      \begin{mathpar}
        \inferrule*[Right=\textsc{TCase}]
          {\Gamma \vdash e : \tau + \sigma \\
            \Gamma \vdash t1 : \tau \rightarrow \rho \\
            \Gamma \vdash t2 : \sigma \rightarrow \rho }
          {\Gamma \vdash \case{e}{t1}{t2} : \rho} \\ \and
        \inferrule*[Right=\textsc{TInl}]
          {\Gamma \vdash t : \tau}
          {\Gamma \vdash \inl{t} : \tau + \sigma} \and
        \inferrule*[Right=\textsc{TInr}]
          {\Gamma \vdash t : \sigma}
          {\Gamma \vdash \inr{t} : \tau + \sigma} \\ \and
        \inferrule*[Right=\textsc{TNVal}]
          {n \in \denoteN}
          {\Gamma \vdash \nval{n} : \<N>} \and
        \inferrule*[Right=\textsc{TNSucc}]
          {\Gamma \vdash t : \<N>}
          {\Gamma \vdash \nsucc{t} : \<N>} \\ \and
        \inferrule*[Right=\textsc{TPrim}]
          {\Gamma \vdash f : \tau \rightarrow \tau \\
            \Gamma \vdash n : \<N> \\
            \Gamma \vdash t : \tau }
          {\Gamma \vdash \nrec{f}{n}{t} : \tau}
      \end{mathpar}
      \caption{Type-inference rules for language constructs for sum types and primitive recursion}
      \label{fig:sum_prim_infer}
    \end{figure}
  \subsection{Arrays}
\section{Optimization}
  \subsection{Program Transformations}
\section{Reverse-Mode AD}
\section{Discussion}
  \subsection{Problems}
  \input{future_work.tex}
\section{Conclusion}

\appendix
\section{Language Definitions}
\section{Forward-Mode Macro}
\section{Denotations}
\printbibliography
\makeatother
\end{document}