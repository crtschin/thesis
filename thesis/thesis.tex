\documentclass[11pt, final]{article}
\usepackage{mystyle}

\addbibresource{./references.bib}

\input{definitions.tex}

\setlength{\headheight}{15pt}
\pagestyle{fancy}
\lhead{Utrecht University}
\rfoot{\thepage}
\cfoot{ }
\allowdisplaybreaks

\begin{document}

\input{titlepage.tex}
\newpage

\input{abstract.tex}
\newpage

\pagenumbering{arabic}
\setcounter{page}{3}
\tableofcontents
\newpage

\input{introduction}

\section{Background}

\input{ad.tex}
\input{denotational.tex}
\input{coq.tex}
\input{logical_relation.tex}

\section{Formalizing Forward-Mode AD}
  We will work out the formalization of automatic differentiation using a source code translating macro in the following sections.
  We start from a base simply-typed lambda calculus extended with product types and incrementally add both sum and array types.

  \subsection{Simply Typed Lambda Calculus}
  % Talk about simply typed lambda calculus,
  % Something about Λ_δ^{+, *, R}
  % Give examples of functions
  % talk about denotations and
  As mentioned in background section \ref{sec:language_repr}, we will make use of De-Bruijn indices in a intrinsic representation to formulate our language.
  Our base language consists of the typed lambda calculus with products and real numbers as ground type, $\Lambda_{\delta}^{\times, \rightarrow, R}$.
  As operations on the real numbers we include both addition and multiplication which are also the functions in $\delta$.

  Both the language constructs and the typing rules for this language are standard for a simply typed lambda calculus, as shown in \ref{fig:base_infer}.
  As expected we include variables, applications and abstractions in the \<var>, \<app> and \<abs> constructors.
  Product types are added to the language in the form of binary projections, \<first> and \<second> to fetch respectively the first and second components of \<tuple>s.
  For real numbers, \<rval> is used to introduce constants and \<add> and \<mul> will be used to respectively encode addition and multiplication.

  \begin{figure}
    \begin{mathpar}
      \inferrule*[Right=\textsc{TVar}]
        {elem\ n\ \Gamma = \tau}
        {\Gamma \vdash var\ n : \tau} \and
      \inferrule*[Right=\textsc{TAbs}]
        {(\sigma, \Gamma) \vdash t : \tau}
        {\Gamma \vdash abs\ t : \sigma \rightarrow \tau} \\ \and
      \inferrule*[Right=\textsc{TApp}]
        {\Gamma \vdash t1 : \sigma \rightarrow \tau \\
          \Gamma \vdash t2 : \sigma}
        {\Gamma \vdash app\ t1\ t2 : \tau} \\ \and
      \inferrule*[Right=\textsc{TTuple}]
        {\Gamma \vdash t1 : \tau \\
          \Gamma \vdash t2 : \sigma}
        {\Gamma \vdash tuple\ t1\ t2 : \tau \times \sigma} \\ \and
      \inferrule*[Right=\textsc{TFst}]
        {\Gamma \vdash t : \tau \times \sigma}
        {\Gamma \vdash first\ t : \tau} \and
      \inferrule*[Right=\textsc{TSnd}]
        {\Gamma \vdash t : \tau \times \sigma}
        {\Gamma \vdash second\ t : \sigma} \\ \and
      \inferrule*[Right=\textsc{TRval}]
        {r \in \<R>}
        {\Gamma \vdash rval\ r : R} \\ \and
      \inferrule*[Right=\textsc{TAdd}]
        {\Gamma \vdash r1 : R \\
          \Gamma \vdash r2 : R \\ }
        {\Gamma \vdash add\ r1\ r2 : R} \and
      \inferrule*[Right=\textsc{TMull}]
        {\Gamma \vdash r1 : R \\
        \Gamma \vdash r2 : R \\ }
      {\Gamma \vdash mul\ r1\ r2 : R} \and
    \end{mathpar}
    \caption{Type-inferrence rules for $\lambdaBase$}
    \label{fig:base_infer}
  \end{figure}

  % How we translated this into the well-typed intrinsic representation
  These can be translated into Coq definitions in a straigtforward manner, with each case keeping track of both how the typing context and types change.
  In the \<var> case we need some way to determine what type the variable is referencing.
  Like many others previously\cite{Benton2011}\cite{Coquand1994}, instead of using numbers accompanied with a proof, we make use of an inductively defined type evidence to type our variables as shown in \ref{lst:strong_stlc}.
  The cases for \<app> and \<abs> are as expected, where variables in the body of abstraction are able to reference their respective arguments.

  In the original proof by Huot, Staton, and \Vakar{} \cite{huot2020correctness}, they make use of n-ary products accompanied with pattern matching expressions. We opted to implement binary projection products, as they are conceptually simpler while still retaining much of the same functionality expected with product types.

  \begin{listing}
    \begin{minted}{coq}
  Definition Ctx : Type := list ty.

  Inductive tm ~(\Gamma : Ctx) : ty \rightarrow Type~ :=
    (* Base STLC *)
    | var : ~forall \tau,
      \tau ∈ \Gamma \rightarrow tm \Gamma \tau~
    | app : ~forall \tau \sigma,
      tm \Gamma (\sigma \Rightarrow \tau) \rightarrow
      tm \Gamma \sigma \rightarrow
      tm \Gamma \tau~
    | abs : ~forall \tau \sigma,
      tm (\sigma::\Gamma) \tau \rightarrow tm \Gamma (\sigma \Rightarrow \tau)~

    (* Operations on real numbers *)
    | const : ~R \rightarrow tm \Gamma Real~
    | add : ~tm \Gamma Real \rightarrow tm \Gamma Real \rightarrow tm \Gamma Real~
    | mul : ~tm \Gamma Real \rightarrow tm \Gamma Real \rightarrow tm \Gamma Real~

    (* Binary projection products *)
    | tuple : ~forall {\tau \sigma},
      tm \Gamma \tau \rightarrow
      tm \Gamma \sigma \rightarrow
      tm \Gamma (\tau \times \sigma)~
    | first : ~forall {\tau \sigma}, tm \Gamma (\tau \times \sigma) \rightarrow tm \Gamma \tau~
    | second : ~forall {\tau \sigma}, tm \Gamma (\tau \times \sigma) \rightarrow tm \Gamma \sigma~
    \end{minted}
    \caption{\<Coq> definition of the base lambda calculus}
    \label{lst:stlc_base}
  \end{listing}

  We use the same inductively defined macro on types and terms to implement forward-mode automatic differentiation as used by many previous authors\cite{huot2020correctness}\cite{barthe2020versatility}\cite{Shaikha2019}.
  The forward-mode macro $\D$ keeps track of both primal and tangent traces using tuples as respectively the first and second subcomponents.
  In most cases, the macro simply preserves the structure of the language.
  In the cases for real numbers such as addition and multiplication, the appropriate implementation corresponding to the derivative needs to be given.

  \begin{align*}
    \D(\<R>) &= \<R> \times \<R>
      & \D(n) &= (n, 0) \\
    \D(\tau \times \sigma) &= \D(\tau) \times \D(\sigma)
      & \D(n + m) &= (n + m, n' + m') \\
    \D(\tau \rightarrow \sigma) &= \D(\tau) \rightarrow \D(\sigma)
      & \D(n * m) &= (n * m, n' * m + m' * n)
    \label{eqn:macro_base}
  \end{align*}

  This is implemented by destructing recursive calls to $\<D>$ to access the syntactic counterparts of the primal and tangent denotations.
  The \<Coq> implementation requires seperate definitions for types, typing contexts and terms, as shown in \ref{lst:macro_base}.
  Note that applying the macro to a variable does nothing as we already apply the macro to the typing context, so variable implicitly reference macro-applied values.

  \begin{listing}
    \begin{minted}{coq}
    \end{minted}
    \caption{Forward-mode macro on the base simply-typed lambda calculus.}
    \label{lst:macro_base}
  \end{listing}

  Due to restricting our language to be total and excluding constructs related to partiality such as general recursion and iteration, it suffices to give our language a set-theoretic denotational semantics. Well-typed terms $\Gamma \vdash t : \tau$ will denotate to functions $\llbracket \Gamma \rrbracket \rightarrow \llbracket \tau \rrbracket$.

  \begin{equation}
    \llbracket t \rrbracket =
      \left\{
        \begin{array}{ll}
          \lambda x. lookup\ \llbracket v \rrbracket\ x
            & : t = \<var>\ v \\
          \lambda x. (\llbracket t1 \rrbracket(x)) (\llbracket t2 \rrbracket(x))
            & : t = \<app>\ t1\ t2 \\
          \lambda x y. \llbracket t \rrbracket(y :: x)
            & : t = \<abs>\ t \\
          const\ n
            & : t = \<rval>\ n \\
          \lambda x. \llbracket t1 \rrbracket(x) + \llbracket t2 \rrbracket(x)
            & : t = \<add>\ t1\ t2 \\
          \lambda x. \llbracket t1 \rrbracket(x) * \llbracket t2 \rrbracket(x)
            & : t = \<mul>\ t1\ t2 \\
          \lambda x. (\llbracket t1 \rrbracket(x), \llbracket t2 \rrbracket(x))
            & : t = \<tuple>\ t1\ t2 \\
          \lambda x. let\ (x, y) = \llbracket t \rrbracket(x)\ in\ x
            & : t = \<first>\ t \\
          \lambda x. let\ (x, y) = \llbracket t \rrbracket(x)\ in\ y
            & : t = \<second>\ t \\
        \end{array}
      \right.
  \label{eqn:lr_base}
  \end{equation}

  For any type $\tau$, simply swap out the syntactic type to its corresponding \<Coq> variant in \<Type>.
  We denotate our typing contexts $\Gamma$, lists of types, as heterogeneous lists containing their corresponding denotations.
  The specific implementation of heterogeneous lists used, correspond to the one given by Adam Chlipala\cite{ChlipalaCPDT}.
  When working through giving the constructs in our language the proper denotations, most of the cases are straigtforward.
  Notable is the case for variables, where we made use of an inductively defined evidence to type our terms.
  As denotations, these evidences wil correspond to lookups into our heterogeneous lists to their appropriate types.

  \begin{listing}
    \begin{minted}{coq}
    \end{minted}
    \caption{Denotatonal semantics for the base simply-typed lambda calculus.}
    \label{lst:denotation_base}
  \end{listing}

  % In the section denotation
  % Explain expressiveness of base language
  % Work out examples
  As mentioned by by Barthe, et. al.\cite{barthe2020versatility}, this small calculus, $\lambdaBase$, accompanied with a very simple denotational semantics is expressive enough to encode all higher-order polynomial functions containing the addition and multiplication operators.

  \begin{example}[Square]
    $abs\ (mul\ (var\ Top)\ (var\ Top))$ denotates to the square function $\lambda x. x * x$.
    \begin{proof}
      This follows from the definition of our denotation functions.
      \begin{align*}
        \llbracket abs\ &(mul\ (var\ Top)\ (var\ Top)) \rrbracket\ [] \\
          &\equiv \lambda x.
            \llbracket mul\ (var\ Top)\ (var\ Top) \rrbracket\ [x] \\
          &\equiv \lambda x.
            \llbracket var\ Top \rrbracket\ [x] *
              \llbracket var\ Top \rrbracket\ [x] \\
          &\equiv \lambda x. x * x \qedhere
      \end{align*}
    \end{proof}
  \end{example}

  % TODO: give reasonable examples

  As we work with denotations, smooth functions $f : \<R>^n -> \<R>$ can be interpreted as the denotations of a corresponding syntactic term $x_1, \dots, x_n \vdash t : R$.
  The idea here is that the free variables in the term $t$ denote the usages of the parameters of the function and as such are restricted to terms of type $R$.
  Note that while both the arguents and result type of $t$ are restricted to $R$, $t$ itself can contain higher order types.

  Although Barthe, et. al.\cite{barthe2020versatility} gave a syntactic proof of correctness of the macro, our proof follows the more denotational style of proof given by Huot, Staton and \Vakar{}\cite{huot2020correctness}.
  We state correctness as the denotation of a macro-applied term will give a pair of both the original function the term represents along with its corresponding derivative.

  The proof of correctness will follow a logical relations argument.Intuitively, the relation will encapsulate idea that derivability is preserved over higher-order types.
  We define a type-indexed logical relation between denotations of both terms and their macro-applied variants, so for any type $\tau$, $S_\tau$ is the relation between functions $R \rightarrow \llbracket \tau \rrbracket$ and $R \rightarrow \llbracket \D(\tau) \rrbracket$.

  \begin{equation}
    S_\tau(f, g) =
      \left\{
        \begin{array}{ll}
          smooth\ f \wedge
            g = \lambda x. (f(x), \frac{\partial f}{\partial x}(x))
            & : \tau = R \\
          \exists f_1, f_2, g_1, g_2,
            & : \tau = \sigma \times \rho \\
            \;\;\;\;S_\sigma(f_1, f_2), S_\sigma(g_1, g_2). \\
            \;\;\;\;f = \lambda x. (f_1(x), g_1(x)) \wedge \\
            \;\;\;\;g = \lambda x. (f_2(x), g_2(x)) \\
          \forall f_1, f_2.
            & : \tau = \sigma \rightarrow \rho \\
            \;\;\;\;S_\sigma(f_1, f_2) \Rightarrow \\
            \;\;\;\;S_\rho(\lambda x. f(x)(f_1(x)),\lambda x. f(x)(f_2(x)))
        \end{array}
      \right.
  \label{eqn:lr_base}
  \end{equation}

  The next step involves proving that syntactically well-typed terms are semantically correct.
  In other words, the relation is valid for any term $x_1, \dots, x_n \vdash t : \tau$ and argument function $f : R \rightarrow R^n$ such that $S_\tau(\llbracket t \rrbracket \circ f, \llbracket \D(t) \rrbracket \circ \D_n \circ f)$.

  To properly instantiate the arguments to the denotation of the macro-applied term, an auxiliary function is needed that pairs each constant with their derivative $0$. So it transforms $f : R \rightarrow \llbracket R^n \rrbracket$ into $\D_n(f, x) : R \rightarrow \llbracket \D(R)^n \rrbracket$.
  The full type signature of the function becomes $\D_n : (R \rightarrow \llbracket R^n \rrbracket) \rightarrow R \rightarrow \llbracket \D(R)^n \rrbracket$, which essentially accompanies each argument supplied by $f$ with its accompanying derivative.

  \begin{equation}
    \D_n(f, x) =
      \left\{
        \begin{array}{ll}
          f(x) & : n = 0 \\
          ((hd \circ f)(x)), \frac{\partial{(hd \circ f)}}{\partial{x}}(x)) :: \D_n(tl \circ f, x) & : n = S n' \\
        \end{array}
      \right.
  \label{eqn:argument_df}
  \end{equation}

  Proving this statement directly by induction on the typing derivation, however, does not work.
  As expected in a logical relations proof, the indicative issue lies in both the case for applications and abstractions.
  To make this work, the correctness statement needs to be generalized to arbitrary contexts and implicitly, substitutions.

  If this were a syntactic proof, one would need to show that relation is preserved when applying substitutions consisting of arbitrary terms, possibly containing higher-order constructs.
  In this style of proof, the same concept needs to be incorporated in the argument function $f$, which intuitively speaking, supplies the terms referenced by variables through the typing context.

  % TODO: attempt to do this?

  To prove this statement, it first needs to be generalized to arbitrary substitutions.
  The key in formulating these denotationally lies in what was previously the argument function $f : R \rightarrow R^n$.
  Previously the function was used to indicate the open variables or function arguments.
  If generalized to $\Gamma = x_1 : \tau_1, \dots, x_n : \tau_n$, this same function could be seen as a function which supplies terms foreach open variable $x_1, \dots, x_n$ with their appropriate types.
  So the argument function now becomes the pair of functions $s : R \rightarrow \llbracket \Gamma \rrbracket$ and $s_D : R \rightarrow \llbracket \D(\Gamma) \rrbracket$.
  Note that the functions $s$ and $s_D$ are built out of the denotations of terms such that these same denotations follow the logical relation (\ref{eqn:lr_base}) for our language.
  We phrase this requirement as a definition.

  \begin{definition}(Instantiation)
    Substitutional functions $s : R \rightarrow \llbracket \Gamma \rrbracket$ and $s_D : R \rightarrow \llbracket \D(\Gamma) \rrbracket$ are inductively instantiated such that they follow
    \begin{equation}
      inst_\Gamma(f, g) =
        \left\{
          \begin{array}{ll}
            f = const([]) \wedge g = const([])
              & : \Gamma = [] \\
            \forall s, s_D.
              & : \Gamma = (\tau :: \Gamma') \\
              \;\;\;\;inst_{\Gamma'}(s, s_D) \wedge S_\tau(f, g)
          \end{array}
        \right.
    \label{eqn:lr_base}
    \end{equation}
  \end{definition}

  Using this notion of substitution instantiations we can now formulate our substitution lemma.

  \begin{lemma}[Substitution]\label{thm:substitution_lemma}
    If for any well-typed term $\Gamma \vdash t : \tau$, and instantiation functions $s : R \rightarrow \llbracket \Gamma \rrbracket$ and $s_D : R \rightarrow \llbracket \D(\Gamma) \rrbracket$ such that they follow $inst_\Gamma(s, s_D)$ then $S_\tau(\llbracket t\rrbracket \circ s, \llbracket \D(t)\rrbracket \circ s_D)$.
  \end{lemma}

  \begin{proof}

    This is proven by induction on the typing derivation of $t$.
    Unless otherwise specified, the type of $s$ and $s_D$ are respectively $R \rightarrow \llbracket \Gamma \rrbracket$ and $R \rightarrow \llbracket \D(\Gamma) \rrbracket$.
    \begin{enumerate}
      \item (\<var>)

        Prove: $S_\tau(\llbracket var\ v \rrbracket \circ s, \llbracket \D(var\ v) \rrbracket \circ s_D)$.

        Proceed by induction on the type evidence $v$.
        \begin{itemize}
          \item(\<Top>) Base case

          Prove: $S_\tau(\llbracket var\ Top \rrbracket \circ s, \llbracket \D(var\ Top) \rrbracket \circ s_D)$, where $s : R \rightarrow \llbracket \tau :: \Gamma \rrbracket$ and $s_D : R \rightarrow \llbracket \tau :: \Gamma \rrbracket$

          In this case the referenced $\tau$ exists at the top of the list.
          So both $\llbracket var\ Top \rrbracket$ and $\llbracket \D(var\ Top) \rrbracket$ denotate to fetching the top term.
          This is now proven by definition of $inst$, which states that the the term is semantically well-typed.

          \begin{align*}
            S&_\tau(\llbracket var\ Top \rrbracket \circ s, \llbracket \D(var\ Top) \rrbracket \circ s_D) \\
            &\Vdash \text{(Definition of $\D$)} \\
            & S_\tau(\llbracket var\ Top \rrbracket \circ s, \llbracket var\ Top \rrbracket \circ s_D) \\
            &\Vdash \text{(Definition of $\circ$)} \\
            & S_\tau(\lambda x. \llbracket var\ Top \rrbracket (s(x)), \lambda x. \llbracket var\ Top \rrbracket (s_D(x))) \\
            &\Vdash \text{(Definition of $\llbracket\rrbracket$)} \\
            & S_\tau(\lambda x. lookup\ \llbracket Top \rrbracket (s(x)), \lambda x. lookup\ \llbracket Top \rrbracket (s_D(x))) \\
            &\Vdash \text{(Rewrite using $s = \lambda x. hd(s(x))::tl(s(x))$)} \\
            & S_\tau(\lambda x. lookup\ \llbracket Top \rrbracket (hd(s(x))::tl(s(x))), \\
              & \;\;\; \lambda x. lookup\ \llbracket Top \rrbracket (hd(s_D(x))::tl(s_D(x)))) \\
            & \Vdash \text{(Simplify with lookup and $\llbracket Top \rrbracket$)} \\
            & S_\tau(\lambda x. hd(s(x)), \lambda x. hd(s_D(x))) \\
            & \Vdash \text{(By definition of $inst_{\tau::\Gamma}$)} \\
          \end{align*} \qed

          \item(\<Pop>) Induction step

          Prove: $S_\tau(\llbracket var\ (Pop\ v) \rrbracket \circ s, \llbracket \D(var\ (Pop\ v)) \rrbracket \circ s_D)$, where $s : R \rightarrow \llbracket \sigma :: \Gamma \rrbracket$ and $s_D : R \rightarrow \llbracket \D(\sigma :: \Gamma) \rrbracket$.

          Induction hypothesis:
          \begin{enumerate}\label{eqn:subst_ih_var_Pop}
            \item $\forall (f : R \rightarrow \llbracket \Gamma \rrbracket), (g : R \rightarrow \llbracket \D(\Gamma) \rrbracket). \\
            \;\;\;S_\tau(\llbracket var\ v \rrbracket \circ f, \llbracket \D(var\ v) \rrbracket \circ g)$
          \end{enumerate}

          Note that the \<var> term now denotates to ignoring the arbitrary unrelated type $\sigma$ and looking up $v$ in the rest of the list $\Gamma$.
          So $S_\tau(\llbracket var\ v \rrbracket \circ tl \circ s, \llbracket \D(var\ v) \rrbracket \circ tl \circ s_D)$, which is proven using the induction hypothesis by respectively instantiating $f$ and $g$ as $tl \circ s$ and $tl \circ s_D$.

          \begin{align*}
            S&_\tau(\llbracket var\ (Pop\ v) \rrbracket \circ s, \llbracket \D(var\ (Pop\ v)) \rrbracket \circ s_D) \\
            &\Vdash \text{(Definition of $\D$)} \\
            & S_\tau(\llbracket var\ (Pop\ v) \rrbracket \circ s, \llbracket var\ (Pop\ v) \rrbracket \circ s_D) \\
            &\Vdash \text{(Definition of $\circ$)} \\
            & S_\tau(\lambda x. \llbracket var\ (Pop\ v) \rrbracket (s(x)), \lambda x. \llbracket var\ (Pop\ v) \rrbracket (s_D(x))) \\
            &\Vdash \text{(Definition of $\llbracket\rrbracket$)} \\
            & S_\tau(\lambda x. lookup\ \llbracket Pop\ v \rrbracket (s(x)), \lambda x. lookup\ \llbracket Pop\ v \rrbracket (s_D(x))) \\
            &\Vdash \text{(Rewrite using $s = \lambda x. hd(s(x))::tl(s(x))$)} \\
            & S_\tau(\lambda x. lookup\ \llbracket Pop\ v \rrbracket (hd(s(x))::tl(s(x))), \\
              & \;\;\; \lambda x. lookup\ \llbracket Pop\ v \rrbracket (hd(s_D(x))::tl(s_D(x)))) \\
            & \Vdash \text{(Simplify with lookup and $\llbracket Pop\ v \rrbracket$)} \\
            & S_\tau(\lambda x. lookup\ \llbracket v \rrbracket (tl(s(x))), \lambda x. lookup\ \llbracket v \rrbracket (tl(s_D(x)))) \\
            & \Vdash \text{(Use IH. \ref{eqn:subst_ih_var_Pop} with $f = tl(s(x))$ and $g = tl(s_D(x))$)}
          \end{align*} \qed
        \end{itemize}
      \item (\<app>)

        Prove: $S_\tau(\llbracket app\ t_1\ t_2 \rrbracket \circ s, \llbracket \D(app\ t_1\ t_2) \rrbracket \circ s_D)$

        Induction hypotheses:
        \begin{enumerate}
          \item \label{eqn:subst_ih_app1}$S_{\sigma\rightarrow\tau}(\llbracket t_1 \rrbracket \circ s, \llbracket \D(t_1) \rrbracket \circ s_D)$
          \item \label{eqn:subst_ih_app2}$S_{\sigma}(\llbracket t_2 \rrbracket \circ s, \llbracket \D(t_2) \rrbracket \circ s_D)$
        \end{enumerate}

        First it is useful to rewrite the induction hypothesis \ref{eqn:subst_ih_app1} in a more usable format. Rewrite the statement using the definition of $S$ at function types.

        \begin{align*}
          S&_{\sigma\rightarrow\tau}(\llbracket t_1 \rrbracket \circ s, \llbracket \D(t_1) \rrbracket \circ s_D) \\
            & \Vdash \text{(Definition of \circ)} \\
            & S_{\sigma\rightarrow\tau}(\lambda x. \llbracket t_1 \rrbracket(s(x)), \lambda x. \llbracket \D(t_1) \rrbracket(s_D(x))) \\
            & \Vdash \text{(Definition of $S_{\rightarrow}$)} \\
            & \forall f_1, f_2.
              S_{\sigma}(f1, f2) \rightarrow \\
            &S_\tau(\lambda x. (\llbracket t_1 \rrbracket(s(x)))(f_1(x)), \lambda x. (\llbracket \D(t_1) \rrbracket(s_D(x)))(f_2(x)))
        \end{align*}

        The case for \<app> is now proven by applying the induction hypothesis \ref{eqn:subst_ih_app1} for the function term using the induction hypothesis \ref{eqn:subst_ih_app2} for the argument term to satify its premise.

        \begin{align*}
          S&_\tau(\llbracket app\ t_1\ t_2 \rrbracket \circ s, \llbracket \D(app\ t_1\ t_2) \rrbracket \circ s_D) \\
            &\Vdash \text{(Definition of $\D$)}\\
            & S_\tau(\llbracket app\ t_1\ t_2 \rrbracket \circ s, \llbracket app\ \D(t_1)\ \D(t_2) \rrbracket \circ s_D) \\
            &\Vdash \text{(Definition of \circ)}\\
            & S_\tau(\lambda x. \llbracket app\ t_1\ t_2 \rrbracket (s (x)), \lambda x. \llbracket app\ \D(t_1)\ \D(t_2) \rrbracket (s_D (x))) \\
            &\Vdash \text{(Definition of $\llbracket \rrbracket$)}\\
            & S_\tau(\lambda x. (\llbracket t_1\ \rrbracket(s(x))) (\llbracket t_2 \rrbracket(s(x))),\lambda x. (\llbracket \D(t_1)\ \rrbracket(s_D(x))) (\llbracket \D(t_2) \rrbracket(s_D(x))) \\
            &\Vdash \text{(Induction hypothesis \ref{eqn:subst_ih_app1})}\\
            & S_{\sigma}(\lambda x. \llbracket t_2 \rrbracket (s(x)), \lambda x. \llbracket \D(t_2) \rrbracket \circ (s_D(x))) \\
            &\Vdash \text{(Induction hypothesis \ref{eqn:subst_ih_app2})}
        \end{align*} \qed
      \item (\<abs>)

        Prove: $S_{\sigma\rightarrow\tau}(\llbracket abs\ t \rrbracket \circ s, \llbracket \D(abs\ t) \rrbracket \circ s_D)$

        Induction hypothesis:
        \begin{enumerate}
          \item \label{eqn:subst_ih_abs} $S_\sigma(\llbracket t \rrbracket \circ s, \llbracket \D(t) \rrbracket \circ s_D)$, where $s : R \rightarrow \llbracket \sigma::\Gamma \rrbracket$ and $s_D : R \rightarrow \llbracket \sigma::\Gamma \rrbracket$
        \end{enumerate}

        As is the case for \ref{eqn:subst_ih_app1}, simplify the goal statement using the definition of $S_\rightarrow$. So the proof obligation now becomes.

        Prove: $S_{\tau}(\lambda x. (\llbracket abs\ t \rrbracket (s(x)))(f_1(x)), \lambda x. (\llbracket \D(abs\ t) \rrbracket (s_D(x)))(f_2(x)))$

        Assume:
        \begin{enumerate}
          \item $f_1 : R \rightarrow \llbracket \sigma \rrbracket$
          \item $f_2 : R \rightarrow \llbracket \D(\sigma) \rrbracket$
          \item \label{eqn:subst_ass_abs3} $S_\sigma(f_1, f_2)$
        \end{enumerate}

        The proof proceeds by rewriting the goal until we can apply the induction hypothesis.
        Note that the assumption \ref{eqn:subst_ass_abs3}: $S_\sigma(f_1, f_2)$ ensures that the requirement of $inst_{\sigma::\Gamma}$ in the induction hypothesis \ref{eqn:subst_ih_abs} is satisfied.

        \begin{align*}
          S&_{\tau}(\lambda x. (\llbracket abs\ t \rrbracket (s(x)))(f_1(x)), \lambda x. (\llbracket \D(abs\ t) \rrbracket (s_D(x)))(f_2(x))) \\
            &\Vdash \text{(Definition of $\D$)}\\
            & S_{\tau}(\lambda x. (\llbracket abs\ t \rrbracket (s(x)))(f_1(x)), \lambda x. (\llbracket abs\ \D(t) \rrbracket (s_D(x)))(f_2(x))) \\
            &\Vdash \text{(Definition of $\llbracket \rrbracket$)}\\
            & S_{\tau}(\lambda x. (\llbracket t \rrbracket (f_1(x) :: s(x))), \lambda x. (\llbracket \D(t) \rrbracket (f_2(x) :: s_D(x)))) \\
            &\Vdash \text{(Induction hypothesis \ref{eqn:subst_ih_app1})}
        \end{align*} \qed

      \item (\<rval>)

      Prove: $S_{R}(\llbracket rval\ n \rrbracket \circ s, \llbracket \D(rval\ n) \rrbracket \circ s_D)$

      This is proven by noting that the corresponding denotations of \<rval> are constant functions, which are both smooth and whose derivatives are equal to $0$.

      \begin{align*}
        S&_R(\llbracket rval\ n \rrbracket \circ s, \llbracket \D(rval\ n) \rrbracket \circ s_D) \\
        &\Vdash \text{(Definition of $\D$)}\\
        &S_R(\llbracket rval\ n \rrbracket \circ s, \llbracket tuple\ (rval\ n)\ (rval\ 0) \rrbracket \circ s_D) \\
        &\Vdash \text{(Definition of $\llbracket\rrbracket$)}\\
        &S_R(const\ n, (const\ n, const\ 0)) \\
        &\Vdash \text{(Definition of $S_R$)}\\
        &smooth\ (const\ n) \wedge
          const\ 0 = \sfrac{\partial{const\ n}}{\partial{x}} \\
        &\Vdash \text{(split goals: goal 1)}\\
        &\;\;\;smooth\ (const\ n) \\
        &\;\;\;\Vdash \text{($f(x) = n$ is continuously differentiable)}\\
        &\Vdash \text{(split goals: goal 2)}\\
        &\;\;\;const\ 0 = \sfrac{\partial{const\ n}}{\partial{x}} \\
        &\;\;\;\Vdash \text{(if $f(x) = n$, then $\sfrac{\partial{f}}{\partial{x}} = 0$)}
      \end{align*} \qed
      \item (\<add>)

      Prove: $S_R(\llbracket add\ t_1\ t_2 \rrbracket \circ s, \llbracket \D(add\ t_1\ t_2) \rrbracket \circ s_D)$

      Induction hypotheses:
      \begin{enumerate}
        \item \label{eqn:subst_ih_add1}$S_R(\llbracket t_1 \rrbracket \circ s, \llbracket \D(t_1) \rrbracket \circ s_D)$
        \item \label{eqn:subst_ih_add2}$S_R(\llbracket t_2 \rrbracket \circ s, \llbracket \D(t_2) \rrbracket \circ s_D)$
      \end{enumerate}

      The proof proceeds by simplifying the denotations and proving the smoothness and derivative requirements for $S_R$.

      \begin{align*}
        S&_R(\llbracket add\ t_1\ t_2 \rrbracket \circ s, \llbracket \D(add\ t_1\ t_2) \rrbracket \circ s_D) \\
        &\Vdash \text{(Definition of $\D$)}\\
        &S_R(\llbracket add\ t_1\ t_2 \rrbracket \circ s, \llbracket tuple\ \\
        & \;\;\;(add\ (first\ \D(t_1)) (first\ \D(t_2)))\ \\
        & \;\;\;(add\ (second \D(t_1)) (second \D(t_2)))) \rrbracket \circ s_D) \\
        &\Vdash \text{(Definition of $\llbracket\rrbracket$, using} \\
        & \;\;\;\;\;\;\;\;\; \text{$(d_1, d_1') = \llbracket \D(t_1) \rrbracket s(x)$ and $(d_2, d_2') = \llbracket \D(t_2) \rrbracket s_D(x)$)}\\
        &S_R(\lambda x. d_1(x) + d_2(x), \lambda x. (d_1(x) + d_2(x), d_1'(x) + d_2'(x))) \\
        &\Vdash \text{(Definition of $S_R$)}\\
        & smooth\ (\lambda x. d_1(x) + d_2(x)) \wedge \\
        & \;\;\; \lambda x. d_1'(x) + d_2'(x) = \sfrac{\partial{(\lambda x. d_1'(x) + d_2'(x))}}{\partial{x}} \\
        &\Vdash \text{(split goals: goal 1)}\\
        &\;\;\;smooth\ (\lambda x. d_1(x) + d_2(x)) \\
        &\;\;\;\Vdash
          \text{(Addition is smooth, if subterms are smooth)}\\
        &\;\;\;smooth\ d_1 \wedge smooth\ d_2 \\
        &\;\;\;\Vdash \text{(Induction hypothesis \ref{eqn:subst_ih_add1} for $d_1$ and \ref{eqn:subst_ih_add2} for $d_2$)}\\
        &\Vdash \text{(split goals: goal 2)}\\
        &\;\;\;\lambda x. d_1'(x) + d_2'(x) = \sfrac{\partial{(\lambda x. d_1'(x) + d_2'(x))}}{\partial{x}} \\
        &\;\;\;\Vdash \text{(By definition of taking the derivative of addition)} \\
        &\;\;\; d_1' = \sfrac{\partial{d_1}}{\partial{x}} \wedge d_2' = \sfrac{\partial{d_2}}{\partial{x}} \\
        &\;\;\;\Vdash \text{(Induction hypothesis \ref{eqn:subst_ih_add1} for $d_1$ and \ref{eqn:subst_ih_add2} for $d_2$)}\\
      \end{align*} \qed

      \item (\<mul>)

      Prove: $S_R(\llbracket mul\ t_1\ t_2 \rrbracket \circ s, \llbracket \D(mul\ t_1\ t_2) \rrbracket \circ s_D)$

      Induction hypotheses:
      \begin{enumerate}
        \item \label{eqn:subst_ih_mul1}$S_R(\llbracket t_1 \rrbracket \circ s, \llbracket \D(t_1) \rrbracket \circ s_D)$
        \item \label{eqn:subst_ih_mul2}$S_R(\llbracket t_2 \rrbracket \circ s, \llbracket \D(t_2) \rrbracket \circ s_D)$
      \end{enumerate}

      Proof goes through almost identically as for the case for \<add>.

      \begin{align*}
        S&_R(\llbracket mul\ t_1\ t_2 \rrbracket \circ s, \llbracket \D(mul\ t_1\ t_2) \rrbracket \circ s_D) \\
        &\Vdash \text{(Definition of $\D$)}\\
        &S_R(\llbracket mul\ t_1\ t_2 \rrbracket \circ s, \llbracket tuple\ \\
        & \;\;\;(mul\ (first\ \D(t_1)) (first\ \D(t_2)))\ \\
        & \;\;\;(add\ \\
        & \;\;\;\;\;(mul\ (first \D(t_1)) (second \D(t_2))) \\
        & \;\;\;\;\;(mul\ (first \D(t_2)) (second \D(t_1)))) \rrbracket \circ s_D) \\
        &\Vdash \text{(Definition of $\llbracket\rrbracket$, using} \\
        & \;\;\;\;\;\;\;\;\; \text{$(d_1, d_1') = \llbracket \D(t_1) \rrbracket s(x)$ and $(d_2, d_2') = \llbracket \D(t_2) \rrbracket s_D(x)$)}\\
        &S_R(\lambda x. d_1(x) * d_2(x), \\
        & \;\;\; \lambda x. (d_1(x) * d_2(x), d_1(x) * d_2'(x) + (d_2(x) * d_1'(x)))) \\
        &\Vdash \text{(Definition of $S_R$)}\\
        &smooth\ (\lambda x. d_1(x) * d_2(x)) \wedge \\
        & \;\;\; \lambda x. d_1(x) * d_2'(x) + d_2(x) * d_1'(x) = \sfrac{\partial{(\lambda x. (d_1(x) * d_2(x))}}{\partial{x}} \\
        &\Vdash \text{(split goals: goal 1)}\\
        &\;\;\;smooth\ (\lambda x. d_1(x) * d_2(x)) \\
        &\;\;\;\Vdash
          \text{(Multiplication is smooth, if subterms are smooth)}\\
        &\;\;\;smooth\ d_1 \wedge smooth\ d_2 \\
        &\;\;\;\Vdash \text{(Induction hypothesis \ref{eqn:subst_ih_mul1} for $d_1$ and \ref{eqn:subst_ih_mul2} for $d_2$)}\\
        &\Vdash \text{(split goals: goal 2)}\\
        &\;\;\;\lambda x. d_1(x) * d_2'(x) + d_2(x) * d_1'(x) = \sfrac{\partial{(\lambda x. (d_1(x) * d_2(x))}}{\partial{x}} \\
        &\;\;\;\Vdash \text{(By definition of taking the derivative of multiplications)} \\
        &\;\;\; d_1' = \sfrac{\partial{d_1}}{\partial{x}} \wedge d_2' = \sfrac{\partial{d_2}}{\partial{x}} \\
        &\;\;\;\Vdash \text{(Induction hypothesis \ref{eqn:subst_ih_mul1} for $d_1$ and \ref{eqn:subst_ih_mul2} for $d_2$)}\\
      \end{align*} \qed

      \item (\<tuple>)

      Prove: $S_(\tau \times \sigma)(\llbracket tuple\ t_1\ t_2 \rrbracket \circ s, \llbracket \D(tuple\ t_1\ t_2) \rrbracket \circ s_D)$

      Induction hypotheses:
      \begin{enumerate}
        \item \label{eqn:subst_ih_tuple1}$S_\tau(\llbracket t_1 \rrbracket \circ s, \llbracket \D(t_1) \rrbracket \circ s_D)$
        \item \label{eqn:subst_ih_tuple2}$S_\sigma(\llbracket t_2 \rrbracket \circ s, \llbracket \D(t_2) \rrbracket \circ s_D)$
      \end{enumerate}

      A recurring pattern will become apparent in later sections when continuing to prove the substitution lemma \ref{thm:substitution_lemma} for types consisting of other types.
      In this case, due to the carefull attention spent on the logical relation, only the witnesses of the subterms of the tuple need to be supplied to finish the proof.

      Note that the witnesses of $S_\tau$ and $S_\sigma$ that need to be given here are supplied by the induction hypotheses.
      While these witnesses are not exactly relevant to finish this proof for \<tuple>, they are needed in the proofs for projections.

      \begin{align*}
        S&_(\tau \times \sigma)(\llbracket tuple\ t_1\ t_2 \rrbracket \circ s, \llbracket \D(tuple\ t_1\ t_2) \rrbracket \circ s_D) \\
        & \Vdash \text{(Definition of $\D$)} \\
        & S_(\tau \times \sigma)(\llbracket tuple\ t_1\ t_2 \rrbracket \circ s, \llbracket tuple\ \D(t_1)\ \D(t_2)) \rrbracket \circ s_D) \\
        & \Vdash \text{(Definition of $\llbracket\rrbracket$)} \\
        & S_(\tau \times \sigma)(\lambda x. (\llbracket t_1 \rrbracket(s(x)), \llbracket t_2 \rrbracket(s(x))), \\
        & \;\;\;\;\;\;\lambda x. (\llbracket \D(t_1) \rrbracket(s'(x)), \llbracket \D(t_2) \rrbracket(s'(x)))) \\
        & \Vdash \text{(Definition of $S_{\tau\times\sigma}$)} \\
        & \exists f_1, f_2, g_1, g_2, \\
            & \;\;\;\;S_\tau(f_1, f_2), S_\sigma(g_1, g_2). \\
            & \;\;\;\;\lambda x. (\llbracket t_1 \rrbracket(s(x)), \llbracket t_2 \rrbracket(s(x))) = \lambda x. (f_1(x), g_1(x)) \wedge \\
            & \;\;\;\;\lambda x. (\llbracket \D(t_1) \rrbracket(s'(x)), \llbracket \D(t_2) \rrbracket(s'(x))) = \lambda x. (f_2(x), g_2(x)) \\
        & \Vdash \text{(Give witnesses: $f_1 := \llbracket t_1 \rrbracket \circ s$, $f_2 := \llbracket t_2 \rrbracket \circ s$,} \\
        & \;\;\;\;\;\; \text{$g_1 := \llbracket \D(t_1) \rrbracket \circ s'$, $g_2 := \llbracket \D(t_2) \rrbracket \circ s'$)} \\
        & \exists S_\tau(f_1, f_2), S_\sigma(g_1, g_2). \\
          & \;\;\;\;\lambda x. (\llbracket t_1 \rrbracket(s(x)), \llbracket t_2 \rrbracket(s(x))) \\
          & \;\;\;\;\;\;\; = \lambda x. (\llbracket t_1 \rrbracket(s(x)), \llbracket t_2 \rrbracket(s(x))) \wedge \\
          & \;\;\;\;\lambda x. (\llbracket \D(t_1) \rrbracket(s'(x)), \llbracket \D(t_2) \rrbracket(s'(x))) \\
          & \;\;\;\;\;\;\; = \lambda x. (\llbracket \D(t_1) \rrbracket(s'(x)), \llbracket \D(t_2) \rrbracket(s'(x))) \\
        & \Vdash \text{(Give witnesses of $S_\tau$ and $S_\sigma$ using respective IHs \ref{eqn:subst_ih_tuple1} and \ref{eqn:subst_ih_tuple2})} \\
        & \;\;\;\;\lambda x. (\llbracket t_1 \rrbracket(s(x)), \llbracket t_2 \rrbracket(s(x))) \\
        & \;\;\;\;\;\;\; = \lambda x. (\llbracket t_1 \rrbracket(s(x)), \llbracket t_2 \rrbracket(s(x))) \wedge \\
        & \;\;\;\;\lambda x. (\llbracket \D(t_1) \rrbracket(s'(x)), \llbracket \D(t_2) \rrbracket(s'(x))) \\
        & \;\;\;\;\;\;\; = \lambda x. (\llbracket \D(t_1) \rrbracket(s'(x)), \llbracket \D(t_2) \rrbracket(s'(x))) \\
        & \Vdash \text{(Reflexivity)} \\
      \end{align*}\qed
      \item (\<first>)

      Prove: $S_(\tau)(\llbracket first\ t \rrbracket \circ s, \llbracket \D(first\ t) \rrbracket \circ s_D)$

      Induction hypotheses:
      \begin{enumerate}
        \item \label{eqn:subst_ih_first}$S_{\tau\times\sigma}(\llbracket t \rrbracket \circ s, \llbracket \D(t) \rrbracket \circ s_D)$
      \end{enumerate}

      Simplifying the induction hypothesis \ref{eqn:subst_ih_first} using the definition of $S_{\tau\times\sigma}$ gives rise to a number of useful assumptions:

      Assumptions:
      \begin{enumerate}
        \item \label{eqn:subst_ass_proj1_0} $f_1 : R \rightarrow \llbracket \tau \rrbracket$
        \item \label{eqn:subst_ass_proj1_1} $f_2 : R \rightarrow \llbracket \D(\tau) \rrbracket$
        \item \label{eqn:subst_ass_proj1_2} $g_1 : R \rightarrow \llbracket \sigma \rrbracket$
        \item \label{eqn:subst_ass_proj1_3} $g_2 : R \rightarrow \llbracket \D(\sigma) \rrbracket$
        \item \label{eqn:subst_ass_proj1_4} $S_\tau(f_1, f_2)$
        \item \label{eqn:subst_ass_proj1_5} $S_\sigma(g_1, g_2)$
        \item \label{eqn:subst_ass_proj1_6} $\llbracket t \rrbracket \circ s = \lambda x. (f_1(x), g_1(x))$
        \item \label{eqn:subst_ass_proj1_7} $\llbracket \D(t) \rrbracket \circ s = \lambda x. (f_2(x), g_2(x))$
      \end{enumerate}

      \begin{align*}
        S&_{\tau}(\llbracket first\ t \rrbracket \circ s, \llbracket \D(first\ t) \rrbracket \circ s_D) \\
        & \Vdash \text{(Rewrite using definition of $\D$)} \\
        & S_{\tau}(\llbracket first\ t \rrbracket \circ s, \llbracket first\ \D(t) \rrbracket \circ s_D) \\
        & \Vdash \text{(Rewrite using definition of $\llbracket\rrbracket$)} \\
        & S_{\tau}(\lambda x. fst(\llbracket t \rrbracket(s(x))), \lambda x. fst(\llbracket \D(t) \rrbracket(s_D(x)))) \\
        & \Vdash \text{(Rewrite using \ref{eqn:subst_ass_proj1_6} and \ref{eqn:subst_ass_proj1_7})} \\
        & S_{\tau}(\lambda x. fst(f_1(x), g_1(x)), \lambda x. fst(f_2(x), g_2(x))) \\
        & \Vdash \text{($\beta\eta$-equality)} \\
        & S_{\tau}(f_1, f_2) \\
        & \Vdash \text{(Assumption \ref{eqn:subst_ass_proj1_4})} \\
      \end{align*} \qed

      \item (\<second>)

      Prove: $S_(\tau)(\llbracket first\ t \rrbracket \circ s, \llbracket \D(first\ t) \rrbracket \circ s_D)$

      Induction hypotheses:
      \begin{enumerate}
        \item \label{eqn:subst_ih_first}$S_{\tau\times\sigma}(\llbracket t \rrbracket \circ s, \llbracket \D(t) \rrbracket \circ s_D)$
      \end{enumerate}

      Proof goes the same as the case for \<first> with the same assumptions following from the induction hypothesis.

      Assumptions:
      \begin{enumerate}
        \item \label{eqn:subst_ass_proj2_0} $f_1 : R \rightarrow \llbracket \tau \rrbracket$
        \item \label{eqn:subst_ass_proj2_1} $f_2 : R \rightarrow \llbracket \D(\tau) \rrbracket$
        \item \label{eqn:subst_ass_proj2_2} $g_1 : R \rightarrow \llbracket \sigma \rrbracket$
        \item \label{eqn:subst_ass_proj2_3} $g_2 : R \rightarrow \llbracket \D(\sigma) \rrbracket$
        \item \label{eqn:subst_ass_proj2_4} $S_\tau(f_1, f_2)$
        \item \label{eqn:subst_ass_proj2_5} $S_\sigma(g_1, g_2)$
        \item \label{eqn:subst_ass_proj2_6} $\llbracket t \rrbracket \circ s = \lambda x. (f_1(x), g_1(x))$
        \item \label{eqn:subst_ass_proj2_7} $\llbracket \D(t) \rrbracket \circ s = \lambda x. (f_2(x), g_2(x))$
      \end{enumerate}

      \begin{align*}
        S&_{\sigma}(\llbracket second\ t \rrbracket \circ s, \llbracket \D(second\ t) \rrbracket \circ s_D) \\
        & \Vdash \text{(Rewrite using definition of $\D$)} \\
        & S_{\sigma}(\llbracket second\ t \rrbracket \circ s, \llbracket second\ \D(t) \rrbracket \circ s_D) \\
        & \Vdash \text{(Rewrite using definition of $\llbracket\rrbracket$)} \\
        & S_{\sigma}(\lambda x. snd(\llbracket t \rrbracket(s(x))), \lambda x. snd(\llbracket \D(t) \rrbracket(s_D(x)))) \\
        & \Vdash \text{(Rewrite using \ref{eqn:subst_ass_proj2_6} and \ref{eqn:subst_ass_proj2_7})} \\
        & S_{\sigma}(\lambda x. snd(f_1(x), g_1(x)), \lambda x. snd(f_2(x), g_2(x))) \\
        & \Vdash \text{($\beta\eta$-equality)} \\
        & S_{\sigma}(f_1, f_2) \\
        & \Vdash \text{(Assumption \ref{eqn:subst_ass_proj2_4})} \\
      \end{align*} \qed
    \end{enumerate}
  \end{proof}

  The proof of the fundamental property of the logical relation now follows from the substitution lemma.



  \begin{theorem}[Fundamental property]
    If for any well-typed term $x_1, \dots, x_n \vdash t : \tau$, and argument function $f : R \rightarrow \llbracket R^n \rrbracket$, such and $s_D : R \rightarrow \llbracket \D(R)^n \rrbracket$ such that they follow $inst_\Gamma(s, s_D)$ then $S_\tau(\llbracket t\rrbracket \circ s, \llbracket \D(t)\rrbracket \circ s_D)$.
  \end{theorem}


  \begin{theorem}[Macro correctness]
    For any term $x_1 : R, ..., x_n : R \vdash t : R$, $\D(t)$ gives the dual number representation of $\llbracket t \rrbracket$.
  \end{theorem}

  \begin{proof}

  \end{proof}



  \subsection{Adding Sums and Primitive Recursion}
  \subsection{Arrays}
\section{Optimization}
  \subsection{Program Transformations}
\section{Reverse-Mode AD}
\section{Discussion}
  \subsection{Problems}
  \subsection{Future Work}
\section{Conclusion}

\appendix
\section{Language Definitions}
\section{Forward-Mode Macro}
\section{Denotations}
\printbibliography
\makeatother
\end{document}