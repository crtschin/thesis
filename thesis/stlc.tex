\subsection{Simply Typed Lambda Calculus}\label{sec:formal_stlc}
  % TODO: Work through MV feedback
  % Talk about simply typed lambda calculus,
  % Something about Λ_δ^{+, *, R}
  % Give examples of functions
  % talk about denotations and
  As mentioned in the background section~\ref{sec:language_repr}, we will make use of De-Bruijn indices in an intrinsic representation to formulate our language.
  We include both addition and multiplication as example operations on the real numbers, but the proofs are easily extensible to other primitive operations.
  Our base language consists of the classic simply-typed lambda calculus with product types and real numbers.

  Both the language constructs and the typing rules for this language are common for a simply-typed lambda calculus, as shown in figure~\ref{fig:base_infer}.
  As expected, we include variables, applications, and abstractions in the language using, respectively, the \<var>, \<app>, and \<abs> terms.
  We work with projection products, whose elimination rules are encoded in the  \<first> and \<second> terms. The \<tuple> term is used to represent the introduction rule.
  For real numbers, \<rval> is used to introduce real numbered constants and \<add> and \<mul> will be used to respectively encode addition and multiplication.

  \begin{figure}
    \begin{mathpar}
      \inferrule*[Right=\textsc{TVar}]
        {elem\ n\ \Gamma = \tau}
        {\Gamma \vdash \var{n} : \tau} \and
      \inferrule*[Right=\textsc{TAbs}]
        {(\sigma, \Gamma) \vdash t : \tau}
        {\Gamma \vdash \abs{t} : \sigma \rightarrow \tau} \\ \and
      \inferrule*[Right=\textsc{TApp}]
        {\Gamma \vdash t1 : \sigma \rightarrow \tau \\
          \Gamma \vdash t2 : \sigma}
        {\Gamma \vdash \app{t1}{t2} : \tau} \\ \and
      \inferrule*[Right=\textsc{TTuple}]
        {\Gamma \vdash t1 : \tau \\
          \Gamma \vdash t2 : \sigma}
        {\Gamma \vdash \tuple{t1}{t2} : \tau \times \sigma} \\ \and
      \inferrule*[Right=\textsc{TFst}]
        {\Gamma \vdash t : \tau \times \sigma}
        {\Gamma \vdash \first{t} : \tau} \and
      \inferrule*[Right=\textsc{TSnd}]
        {\Gamma \vdash t : \tau \times \sigma}
        {\Gamma \vdash \second{t} : \sigma} \\ \and
      \inferrule*[Right=\textsc{TRVal}]
        {r \in \denR}
        {\Gamma \vdash \rval{r} : \synR} \\ \and
      \inferrule*[Right=\textsc{TAdd}]
        {\Gamma \vdash r1 : \synR \\
          \Gamma \vdash r2 : \synR \\ }
        {\Gamma \vdash \add{r1}{r2} : \synR} \and
      \inferrule*[Right=\textsc{TMull}]
        {\Gamma \vdash r1 : \synR \\
        \Gamma \vdash r2 : \synR \\ }
      {\Gamma \vdash \mul{r1}{r2} : \synR} \and
    \end{mathpar}
    \caption{Type-inference rules for the base simply-typed lambda calculus}
    \label{fig:base_infer}
  \end{figure}

  % How we translated this into the well-typed intrinsic representation
  These can be translated into \<Coq> definitions in a reasonably straightforward manner, with each case keeping track of both how the typing context and types change.
  In the \<var> case, we need some way to determine what type the variable is referencing.
  Like many others previously\cite{Benton2011}\cite{Coquand1994}, instead of using indices into the list accompanied by a proof that the index does not exceed the length of the list, we make use of an inductively defined type evidence to type our variables as shown in code snippet~\ref{lst:strong_stlc}.
  The cases for \<app> and \<abs> are as expected, where variables in the body of abstractions can reference their respective arguments.

  Note that in the original proof by Huot, Staton, and \Vakar{} \cite{huot2020correctness}, they made use of n-ary products accompanied by pattern matching expressions.
  We opted to implement binary projection products, as these are conceptually simpler while still retaining much of the same functionality expected of product types.

  \begin{listing}
    \begin{minted}{coq}
      Inductive tm ~(\Gamma : Ctx) : ty \rightarrow Type~ :=
        ...
        (* Binary projection products *)
        | tuple : ~forall {\tau \sigma},
          tm \Gamma \tau \rightarrow
          tm \Gamma \sigma \rightarrow
          tm \Gamma (\tau \synStar \sigma)~
        | first : ~forall {\tau \sigma}, tm \Gamma (\tau \synStar \sigma) \rightarrow tm \Gamma \tau~
        | second : ~forall {\tau \sigma}, tm \Gamma (\tau \synStar \sigma) \rightarrow tm \Gamma \sigma~
        (* Operations on reals *)
        | rval : ~forall r, tm \Gamma $\synR$~
        | add : ~tm \Gamma $\synR$ \rightarrow tm \Gamma $\synR$ \rightarrow tm \Gamma $\synR$~
        | mul : ~tm \Gamma $\synR$ \rightarrow tm \Gamma $\synR$ \rightarrow tm \Gamma $\synR$~
    \end{minted}
    \caption{Terms in our language related to product and real types.}
    \label{lst:stlc_prod_r}
  \end{listing}

  % \begin{listing}
  %   \begin{minted}{coq}
  % Definition Ctx : Type := list ty.

  % Inductive tm ~(\Gamma : Ctx) : ty \rightarrow Type~ :=
  %   (* Base STLC *)
  %   | var : ~forall \tau,
  %     \tau ∈ \Gamma \rightarrow tm \Gamma \tau~
  %   | app : ~forall \tau \sigma,
  %     tm \Gamma (\sigma \Rightarrow \tau) \rightarrow
  %     tm \Gamma \sigma \rightarrow
  %     tm \Gamma \tau~
  %   | abs : ~forall \tau \sigma,
  %     tm (\sigma::\Gamma) \tau \rightarrow tm \Gamma (\sigma \Rightarrow \tau)~

  %   (* Operations on real numbers *)
  %   | const : ~R \rightarrow tm \Gamma Real~
  %   | add : ~tm \Gamma Real \rightarrow tm \Gamma Real \rightarrow tm \Gamma Real~
  %   | mul : ~tm \Gamma Real \rightarrow tm \Gamma Real \rightarrow tm \Gamma Real~

  %   (* Binary projection products *)
  %   | tuple : ~forall {\tau \sigma},
  %     tm \Gamma \tau \rightarrow
  %     tm \Gamma \sigma \rightarrow
  %     tm \Gamma (\tau \times \sigma)~
  %   | first : ~forall {\tau \sigma}, tm \Gamma (\tau \times \sigma) \rightarrow tm \Gamma \tau~
  %   | second : ~forall {\tau \sigma}, tm \Gamma (\tau \times \sigma) \rightarrow tm \Gamma \sigma~
  %   \end{minted}
  %   \caption{\<Coq> definition of the base lambda calculus}
  %   \label{lst:stlc_base}
  % \end{listing}

  % TODO: Find better origins of this macro
  We use the same inductively defined macro on types and terms used by many previous authors to implement the forward-mode automatic differentiation macro\cite{huot2020correctness}\cite{barthe2020versatility}\cite{Shaikha2019}.
  The forward-mode macro, $\D$, keeps track of both primal and tangent traces using tuples as respectively its first and second elements.
  In most cases, the macro simply preserves the structure of the language.
  The cases for real numbers such as addition and multiplication are the exception.
  Here, the element encoding the tangent trace needs to contain the proper syntactic translation of the derivative of the operation.

  Due to the intrinsic nature of our language representation, the macro also needs to be applied to both the types and typing context to ensure that the terms remain well-typed.
  In other words, for any well-typed term $\Gamma \vdash t : \tau$, applying the forward-mode macro results in a well-typed term in the macro-expanded context, $\D(\Gamma) \vdash \D(t) : \D(\tau)$.

  \begin{figure}[H]
    \centering
    \begin{equation*}
      \begin{split}
        \D(\synR) &= \synR \synStar \synR \\
        \D(\tau \synStar \sigma) &= \D(\tau) \synStar \D(\sigma) \\
        \D(\tau \synFunc \sigma) &= \D(\tau) \synFunc \D(\sigma)
      \end{split}
      \;\;\;\;\;\;
      \begin{split}
        \D(\rval{n}) &= \tuple{(\rval{n})}{(\rval{0})} \\
        \D(\add{n}{m}) &= \tuple{(\add{n}{m})}{(\add{n'}{m'})} \\
        \D(\mul{n}{m}) &= \tuple{(\mul{n}{m})} \\
          &{(\add{(\mul{n'}{m})}{(\mul{m'}{n})})})
      \end{split}
    \end{equation*}
    \caption{Macro on base simply-typed lambda calculus}
    \label{eqn:macro_base}
  \end{figure}

  Applying the macro to a term gives the syntactic counterparts of both their primal and tangent denotations as a tuple.
  These terms can be accessed with projections to implement the various derivative implementations of the operations on real terms included in the language.
  Note that applying the macro to the case for variables does nothing as the macro is also applied to the typing context, so variables implicitly already reference macro-applied terms.

  As we restrict our language to total constructions and excluding concepts such as general recursion and iteration, it suffices to give our language a set-theoretic denotational semantics.
  In this case the types $\synR, \synFunc, \synStar$ directly correspond to their \<Coq> equivalent, respectively $\denR, \denFunc, \denStar$.
  Well-typed terms of type $\tau$, given typing context $\Gamma$, will denotate to functions $\llbracket \Gamma \rrbracket \to \llbracket \tau \rrbracket$.

  \begin{figure}
    \centering
    \begin{gather*}
      \begin{aligned}
        \llbracket \synR \rrbracket &= \denR \\
        \llbracket \tau \synStar \sigma \rrbracket &=
          \llbracket \tau \rrbracket \denStar \llbracket \sigma \rrbracket \\
        \llbracket \tau \synFunc \sigma \rrbracket &= \llbracket \tau \rrbracket \denFunc \llbracket \sigma \rrbracket \\
        \\
        \llbracket \<Top> \rrbracket &= \<hd> \\
        \llbracket \<Pop>\ v \rrbracket &= \llbracket v \rrbracket \circ \<tl> \\
      \end{aligned}
      \;\;\;\;\;\;
      \begin{aligned}
        \llbracket \var{v} \rrbracket &=
          \lambda x. lookup\ \llbracket v \rrbracket\ x \\
        \llbracket \app{t_1}{t_2} \rrbracket &=
          \lambda x. (\llbracket t_1 \rrbracket(x)) (\llbracket t_2 \rrbracket(x)) \\
        \llbracket \abs{t} \rrbracket &=
          \lambda x\ y. \llbracket t \rrbracket(y :: x) \\
        \llbracket \add{t_1}{t_2} \rrbracket &=
          \lambda x. \llbracket t_1 \rrbracket(x) + \llbracket t_2 \rrbracket(x) \\
        \llbracket \mul{t_1}{t_2} \rrbracket &=
          \lambda x. \llbracket t_1 \rrbracket(x) * \llbracket t_2 \rrbracket(x) \\
        \llbracket \tuple{t_1}{t_2} \rrbracket &=
          \lambda x. (\llbracket t_1 \rrbracket(x), \llbracket t_2 \rrbracket(x)) \\
        \llbracket \first{t} \rrbracket &=
          \lambda x. fst(\llbracket t \rrbracket(x)) \\
        \llbracket \second{t} \rrbracket &=
          \lambda x. snd(\llbracket t \rrbracket(x)) \\
      \end{aligned} \\ \\
      \begin{aligned}
        fst &=
          \lambda x. let\ (x, y) \coloneqq \llbracket t \rrbracket(x)\ in\ x \\
        snd &=
          \lambda x. let\ (x, y) \coloneqq \llbracket t \rrbracket(x)\ in\ y \\
      \end{aligned}
    \end{gather*}
    \caption{Denotations of the base simply-typed lambda calculus}
    \label{eqn:denotation_base}
  \end{figure}

  Denotating the terms in our language now corresponds to finding the appropriate inhabitants in the denotated types.
  As typing contexts, $\Gamma$, are represented by lists of types.
  The appropriate way to denotate these would be to map the denotation function over the list.
  The resulting heterogeneous list contains the denotations of each type in the list in the correct order.
  The specific implementation of heterogeneous lists used in the proof corresponds to the one given by Adam Chlipala\cite{ChlipalaCPDT}.
  In this implementation, heterogeneous lists consist of an underlying list of some type $A$ and an accompanying function $A \to Set$, which in our use case are, respectively, the typing context and the denotation function.

  When giving the constructs in our language their proper denotations, most of the cases are straightforward.
  Notable is the case for variables, where we made use of the inductively defined type evidence to type our terms.
  Remember that to type variables in our term language, we have to also give the exact position of the type we are referencing in the typing context.
  Similarly as denotations, we are able to transform this positional information to generate a specialized lookup function, which given a valid typing context, gives a term denotation with the correct type.
  Essentially, we do a lookup into the heterogeneous list of denotations corresponding to the typing context.

  \begin{minted}{coq}
    Equations denote_v ~$\Gamma$~ ~$\tau$~ (v: ~$\tau \in \Gamma$~) : ~$\llbracket \Gamma \rrbracket \rightarrow \llbracket \tau \rrbracket$~ :=
    denote_v (Top ~$\Gamma$~ ~$\tau$~) := hd;
    denote_v (Pop ~$\Gamma$~ ~$\tau$~ ~$\sigma$~ v) := denote_v v ~$\circ$~ tl.
  \end{minted}

  % \begin{listing}
  %   \begin{minted}{coq}
  %   \end{minted}
  %   \caption{Denotatonal semantics for types, typing contexts and lookups.}
  %   \label{lst:denotation_types}
  % \end{listing}

  % \begin{listing}
  %   \begin{minted}{coq}
  %   \end{minted}
  %   \caption{Denotatonal semantics for the base simply-typed lambda calculus.}
  %   \label{lst:denotation_base}
  % \end{listing}

  % In the section denotation
  % Explain expressiveness of base language
  % Work out examples

  % As mentioned by by Barthe, et al.\cite{barthe2020versatility}, this small calculus, $\lambdaBase$, accompanied with the arguably simple set-theoretic denotational semantics is expressive enough to encode the higher-order polynomials containing the addition and multiplication operators.

  \begin{example}[Square]
    $abs\ (mul\ (var\ Top)\ (var\ Top))$ denotates to the square function $\lambda x. x * x$.
    \begin{proof}
      This follows from the definition of our denotation functions.
      \begin{align*}
        \llbracket abs\ &(mul\ (var\ Top)\ (var\ Top)) \rrbracket\ [] \\
          &\equiv \lambda x.
            \llbracket mul\ (var\ Top)\ (var\ Top) \rrbracket\ [x] \\
          &\equiv \lambda x.
            \llbracket var\ Top \rrbracket\ [x] *
              \llbracket var\ Top \rrbracket\ [x] \\
          &\equiv \lambda x. x * x \qedhere
      \end{align*}
    \end{proof}
  \end{example}

  % TODO: give reasonable examples

  Using the denotation rules in Figure~\ref{eqn:denotation_base}, syntactically well-typed terms in our language of the form $x_1 : \synR, \dots, x_n : \synR \vdash t : \synR$ can be interpreted as their corresponding smooth functions $f : \denR^n \to \denR$.
  Intuitively, the free variables in the syntactic term $t$ correspond to the parameters of the denotation function $f$.

  Although Barthe, et al.\cite{barthe2020versatility} gave a syntactic proof of correctness of the macro, our formal proof follows the more denotational style of proof given by Huot, Staton and \Vakar{}\cite{huot2020correctness}.
  Likewise, our proof of correctness will follow a similar logical relations argument.
  While both approaches have their merits, the proof using the denotational semantics requires less technical bookkeeping of open and closed terms.

  Informally, the correctness statement of the forward-mode macro will consists of the assertion that the denotation of any macro-applied term of type $x_1 : \synR, \dots, x_n : \synR \vdash t : \synR$ will result in a pair of both the denotation of the original term and the derivative of that denotation.
  Note that while both the free variables and result type of the term $t$ are restricted to type $\synR$, $t$ itself can contain subterms of higher-order types.

  The logical relation will ensure that both the smoothness property and the derivatives are preserved over higher-order types.
  We define the logical relation as a type-indexed relation between denotations of both terms and their macro-applied variants, so for any type $\tau$, $S_\tau$ is the relation between functions $R \rightarrow \llbracket \tau \rrbracket$ and $R \rightarrow \llbracket \D(\tau) \rrbracket$.

  When $\tau = \synR$, the denotation of the macro-applied term should give both the original denotation and its derivative.
  With function types, as long as the relation is valid for the argument, applying these argument functions to the tracked denotations should preserve the relation.
  Some care has to be taken in the case for products.
  Notably, the denotations of the subterms, $R \rightarrow \llbracket \tau \rrbracket$ and $R \rightarrow \llbracket \sigma \rrbracket$, should be existentially quantified as these are dependent on the original denotation $R \rightarrow \llbracket \tau \times \sigma \rrbracket$.

  \begin{definition}(Logical relation)
    Denotation functions $f$ and their corresponding derivatives $g$ are inductively defined on the structure of our types such that they follow the relation
    \begin{equation}
      S_\tau(f, g) =
        \left\{
          \begin{array}{ll}
            smooth\ f \wedge
              g = \lambda x. (f(x), \frac{\partial f}{\partial x}(x))
              & : \tau = R \\
            \exists f_1, f_2, g_1, g_2,
              & : \tau = \sigma \times \rho \\
              \;\;\;\;S_\sigma(f_1, f_2), S_\sigma(g_1, g_2). \\
              \;\;\;\;f = \lambda x. (f_1(x), g_1(x)) \wedge \\
              \;\;\;\;g = \lambda x. (f_2(x), g_2(x)) \\
            \forall f_1, f_2.
              & : \tau = \sigma \rightarrow \rho \\
              \;\;\;\;S_\sigma(f_1, f_2) \Rightarrow \\
              \;\;\;\;S_\rho(\lambda x. f(x)(f_1(x)),\lambda x. f(x)(f_2(x)))
          \end{array}
        \right.
    \label{eqn:lr_base}
    \end{equation}
  \end{definition}

  The next step involves proving that syntactically well-typed terms are semantically correct.
  In other words, the relation needs to be proven valid for any term $x_1 : \synR, \dots, x_n : \synR \vdash t : \tau$ and argument function $f : \denR \rightarrow \denR^n$ such that $S_\tau(\llbracket t \rrbracket \circ f, \llbracket \D(t) \rrbracket \circ \D_n \circ f)$.
  To properly instantiate the arguments to the denotation of the macro-applied term, an auxiliary function is needed that pairs each constant with their derivative $0$. So it transforms the argument function $f : \denR \rightarrow \llbracket \synR^n \rrbracket$ into one that supplies both the original input value and its accompanying derivative.
  The full type signature of this auxiliary function is $\D_n : (\denR \rightarrow \llbracket \synR^n \rrbracket) \rightarrow \denR \rightarrow \llbracket \D(\synR)^n \rrbracket$. Note that $\tau^n$ is used as syntactic sugar for $\synRepeat{\tau}{n}$ and is simply a typing context consisting of the type $\tau$ repeated $n$ times.

  \begin{equation}
    \D_n(f, x) =
      \left\{
        \begin{array}{ll}
          f(x) & : n = 0 \\
          ((hd \circ f)(x), \frac{\partial{(hd \circ f)}}{\partial{x}}(x)) :: \D_{n'}(tl \circ f, x) & : n = n' + 1 \\
        \end{array}
      \right.
  \label{eqn:argument_df}
  \end{equation}

  Proving this statement directly by induction on the typing derivation, however, does not work.
  As expected in a logical relations proof, the indicative issue lies in both the case for applications and abstractions.
  To make this work, the correctness statement needs to be generalized to arbitrary contexts and implicitly, substitutions.
  If this were a syntactic proof, one would need to show that the relation is preserved when applying substitutions consisting of arbitrary terms, possibly containing higher-order constructs.
  In this style of proof, however, the same concept needs to be formulated in a denotational manner.

  The key in formulating these denotationally lies in the argument function $f : \denR \to \denR^n$.
  Previously the function was used to indicate the open variables or function arguments.
  Generalized to $\Gamma = x_1 : \tau_1, \dots, x_n : \tau_n$, this function can be interpreted as supplying for each open variable $x_1, \dots, x_n$ a corresponding denotated term with type $\llbracket \tau_1 \rrbracket, \dots, \llbracket \tau_n \rrbracket$.
  So the argument function now becomes the pair of functions $s : R \rightarrow \llbracket \Gamma \rrbracket$ and $s_D : R \rightarrow \llbracket \D(\Gamma) \rrbracket$, which intuitively speaking, form the denotational counterparts of syntactic substitutions.
  Notably, for the functions $s$ and $s_D$ to be valid with respect to the logical relation, they are required to be built from the denotations of terms such that these denotations also follow the logical relation.
  We phrase this requirement as a definition.

  \begin{definition}(Instantiation)
    Instantiation functions $s : R \rightarrow \llbracket \Gamma \rrbracket$ and $s_D : R \rightarrow \llbracket \D(\Gamma) \rrbracket$ are inductively defined such that they follow
    \begin{equation}
      inst_\Gamma(f, g) =
        \left\{
          \begin{array}{ll}
            f = (\lambda x. \denNil) \wedge g = (\lambda x. \denNil)
              & : \Gamma = \denNil \\
            \forall f_1, f_2, g_1, g_2.
              & : \Gamma = (\tau :: \Gamma') \\
              \;\;inst_{\Gamma'}(f_1, g_1) \wedge S_\tau(f_2, g_2) \\
              \;\;\;\; \to f = (\lambda x. f_2(x) :: f_1(x)) \wedge \\
              \;\;\;\;\;\; g = (\lambda x. g_2(x) :: g_1(x))
          \end{array}
        \right.
    \label{eqn:inst_base}
    \end{equation}
  \end{definition}

  Using this notion of instantiations we can now formulate our fundamental lemma. Informally, this states that given correct instantiation functions any well-typed term is semantically correct with respect to the logical relation.

  \begin{lemma}[Fundamental]\label{thm:fundamental_lemma}
    For any well-typed term $\Gamma \vdash t : \tau$, and instantiation functions $s : R \rightarrow \llbracket \Gamma \rrbracket$ and $s_D : R \rightarrow \llbracket \D(\Gamma) \rrbracket$ such that they follow $inst_\Gamma(s, s_D)$, we have that $S_\tau(\llbracket t\rrbracket \circ s, \llbracket \D(t)\rrbracket \circ s_D)$.
  \end{lemma}

  % \input{proof_base.tex}

  \begin{proof}
    This is proven by induction on the typing derivation of the well-typed term $t$. The majority of cases follow from the induction hypothesis.
    The case for \<var> follows from $inst$ which ensures that any term referenced is semantically well-typed with respect to the relation.
    Proving the cases used to encode the operators on reals such as \<add> and \<mul> involve proving both smoothness and giving the witness of the derivative.
  \end{proof}

  We can derive the fundamental property of the base logical relation directly from the fundamental lemma.
  This involves proving the prerequisite $inst$ we used previously.
  Note that the correctness of both the macro and the fundamental property is dependent on the requirement that the denotations supplied by the argument function are smooth.

  \begin{corollary}[Fundamental property]\label{thm:fundamental_property}
    For any term $x_1 : \synR, \dots, x_n : \synR \vdash t : \synR$, $\llbracket\D(t)\rrbracket$ gives the dual number representation of $\llbracket t \rrbracket$, such that for any argument function $f : \denR \to \denR^n$, we have that $S_\tau(\llbracket t\rrbracket \circ f, \llbracket \D(t)\rrbracket \circ \D_n \circ f)$.
  \end{corollary}

  \begin{proof}
    This follows from the fundamental lemma. We lastly need to prove $\inst{(\synRepeat{\synR}{n})}$.
    This is proven by induction on $n$.
    If $n = 0$, the goal is trivial due to the argument function $f$ being extensionally equal to $\synConst{[]}$, which directly corresponds to $\inst{[]}$.
    The induction step is proven by both the induction hypothesis and the assumption that the denotations of the arguments supplied are smooth.
  \end{proof}

  \begin{theorem}[Macro correctness]\label{thm:macro_correctness}
    For any term $x_1 : \synR, \dots, x_n : \synR \vdash t : \synR$, $\llbracket\D(t)\rrbracket$ gives the dual number representation of $\llbracket t \rrbracket$, such that for any argument function $f : \denR \rightarrow \denR^n$, we have that $\llbracket \D(t) \rrbracket \circ \D_n \circ f = \lambda x. (\llbracket t \rrbracket \circ f, \sfrac{\partial{(\llbracket t \rrbracket \circ f)}}{\partial{x}})$.
  \end{theorem}

  \begin{proof}
    This is proven by showing that the goal follows from the logical relation which itself is implied by the fundamental property.

    \begin{align*}
      \llbracket \D(t) &\rrbracket \circ \D_n \circ f = \lambda x. (\llbracket t \rrbracket \circ f, \sfrac{\partial{(\llbracket t \rrbracket \circ f)}}{\partial{x}}) \\
      & \Vdash \text{(By definition of $S_R$ with $f := \llbracket t \rrbracket \circ f$ and $g := \llbracket \D(t) \rrbracket \circ \D_n \circ f$)} \\
      & S_R(\llbracket t \rrbracket \circ f, \llbracket \D(t) \rrbracket \circ \D_n \circ f) \\
      & \Vdash \text{(Fundamental property (\ref{thm:fundamental_property}))}
    \end{align*}
  \end{proof}
